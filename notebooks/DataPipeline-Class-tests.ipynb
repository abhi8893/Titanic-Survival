{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../titansurv/pipeline/data_pipeline.py:42: UserWarning: Please set the data first using set_data method!\n",
      "  warnings.warn('Please set the data first using set_data method!')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import titansurv\n",
    "from titansurv.pipeline import DataPipeline\n",
    "from titansurv.preprocessing.transformers import NaNDropper\n",
    "from titansurv.utils import print_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/raw/train.csv\").drop('PassengerId', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Name      891 non-null    object \n",
      " 3   Sex       891 non-null    object \n",
      " 4   Age       714 non-null    float64\n",
      " 5   SibSp     891 non-null    int64  \n",
      " 6   Parch     891 non-null    int64  \n",
      " 7   Ticket    891 non-null    object \n",
      " 8   Fare      891 non-null    float64\n",
      " 9   Cabin     204 non-null    object \n",
      " 10  Embarked  889 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 76.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following were the preprocessing steps used: \n",
    "1. **Embarked**: Dropped NA rows and applied OneHotEncoding\n",
    "2. **Age** : Applied Mean Imputation and Mean Normalization\n",
    "3. **Fare**: Mean Normalization\n",
    "4. **Sex**: OneHotEncoding\n",
    "5. **Name**: Categorised into ['Mr', 'Mrs', 'Miss', 'Master', 'Special']<br/> \n",
    "    5.1 Rename [Mlle, Ms] -> Miss      \n",
    "    5.2 Rename [Mme] -> Mrs     \n",
    "    5.3 Put the Rest -> Special     \n",
    "    Then performed OneHotEncoding\n",
    "6. **Ticket** categorized into [1: numeric, 0: else] <br/>\n",
    "    6.1 Remove special characters but not space <br/>\n",
    "    6.2 Replace numeric strings by 'numeric' <br/>\n",
    "    6.3 Split on space and keep the first item <br/>\n",
    " Then applied binarizer for [1: numeric, 0: else]\n",
    "7. **SibSp** binned into [0, 1, >1] and applied OneHotEncoding\n",
    "8. **Parch** binned into [0, 1, >1] and applied OneHotEncoding\n",
    "\n",
    "Tuned ML model: **RandomForestClassifier** using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = r'''The following were the preprocessing steps used: \n",
    "1. **Embarked**: Dropped NA rows and applied OneHotEncoding\n",
    "2. **Age** : Applied Mean Imputation and Mean Normalization\n",
    "3. **Fare**: Mean Normalization\n",
    "4. **Sex**: OneHotEncoding\n",
    "5. **Name**: Categorised into ['Mr', 'Mrs', 'Miss', 'Master', 'Special']<br/> \n",
    "    5.1 Rename [Mlle, Ms] -> Miss      \n",
    "    5.2 Rename [Mme] -> Mrs     \n",
    "    5.3 Put the Rest -> Special     \n",
    "    Then performed OneHotEncoding\n",
    "6. **Ticket** categorized into [1: numeric, 0: else] <br/>\n",
    "    6.1 Remove special characters but not space <br/>\n",
    "    6.2 Replace numeric strings by 'numeric' <br/>\n",
    "    6.3 Split on space and keep the first item <br/>\n",
    " Then applied binarizer for [1: numeric, 0: else]\n",
    "7. **SibSp** binned into [0, 1, >1] and applied OneHotEncoding\n",
    "8. **Parch** binned into [0, 1, >1] and applied OneHotEncoding\n",
    "\n",
    "Tuned ML model: **RandomForestClassifier** using GridSearchCV'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FE_SibSp(arr: np.array):\n",
    "    arr = arr.copy()\n",
    "    arr[arr>1] = 2\n",
    "    if len(arr.shape) == 1:\n",
    "        arr = arr.reshape(-1, 1)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def FE_Parch(arr: np.array):\n",
    "    arr = arr.copy()\n",
    "    arr[arr>1] = 2\n",
    "    if len(arr.shape) == 1:\n",
    "        arr = arr.reshape(-1, 1)\n",
    "    return arr\n",
    "\n",
    "def FE_Ticket(x):\n",
    "    x = x.str.replace(r'[^A-Za-z0-9\\s]+', '')\n",
    "    x = x.apply(lambda x: x.split(' ')[0] if not x.isdigit() else 'numeric')\n",
    "    \n",
    "    return x.values.reshape(-1, 1)\n",
    "\n",
    "def FE_Name(x, pattern='([A-Z][a-z]+)\\.'):\n",
    "    x = x.apply(lambda x: re.search(pattern, x).group(1))\n",
    "    x.replace(['Mlle', 'Ms'], 'Miss', inplace=True)\n",
    "    x.replace(['Mme'], 'Mrs', inplace=True)\n",
    "    x.loc[~x.isin(['Mr', 'Mrs', 'Miss', 'Master'])] = 'Special'\n",
    "    return x.values.reshape(-1, 1)\n",
    "\n",
    "\n",
    "def FE_Cabin(x):\n",
    "    col1 = x.str[0].fillna('NC')\n",
    "    return col1.values.reshape(-1, 1)\n",
    "\n",
    "@np.vectorize\n",
    "def binary_enc(x):\n",
    "    if x == 'numeric':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "binarizer = FunctionTransformer(binary_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data = Pipeline([\n",
    "    ('nan_drpr', NaNDropper(['Embarked']))\n",
    "])\n",
    "\n",
    "pre2 = Pipeline([\n",
    "    ('imp', SimpleImputer()),\n",
    "    ('scaler', StandardScaler())\n",
    "], 'passthrough')\n",
    "\n",
    "pre_Name = Pipeline([\n",
    "    ('featurize', FunctionTransformer(FE_Name)),\n",
    "    ('enc', OneHotEncoder(categories=[['Mr', 'Mrs', 'Miss', 'Master', 'Special']],\n",
    "                          drop='first'))\n",
    "])\n",
    "\n",
    "# TODO: Implement modify pipeline function for DRY\n",
    "pre_Cabin = Pipeline([\n",
    "    ('featurize', FunctionTransformer(FE_Cabin)),\n",
    "    ('enc', OneHotEncoder(categories=[['A', 'B', 'C', 'D', \n",
    "                                      'E', 'F', 'G', 'T', 'NC']], \n",
    "                          drop='first'))\n",
    "])\n",
    "\n",
    "pre_Ticket = Pipeline([\n",
    "    ('featurize', FunctionTransformer(FE_Ticket)),\n",
    "    ('binarizer', binarizer)\n",
    "])\n",
    "\n",
    "pre_SibSp = Pipeline([\n",
    "    ('binner', FunctionTransformer(FE_SibSp)),\n",
    "    ('enc', OneHotEncoder(drop='first'))\n",
    "])\n",
    "\n",
    "pre_Parch = Pipeline([\n",
    "    ('binner', FunctionTransformer(FE_Parch)),\n",
    "    ('enc', OneHotEncoder(drop='first'))\n",
    "])\n",
    "\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    ('enc', OneHotEncoder(drop='first'), ['Sex', 'Embarked']),\n",
    "    ('imp_scaler', pre2, ['Age', 'Fare']),\n",
    "    ('pre_Name', pre_Name, 'Name'),\n",
    "    ('pre_Cabin', pre_Cabin, 'Cabin'),\n",
    "    ('pre_Ticket', pre_Ticket, 'Ticket'),\n",
    "    ('Pre_SibSp', pre_SibSp, ['SibSp']),\n",
    "    ('Pre_Parch', pre_Parch, ['Parch'])\n",
    "], \n",
    "    'passthrough')\n",
    "\n",
    "mlmodel = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataPipeline(prepare_data, preprocess, mlmodel, df, 'Survived', description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     Pclass                                               Name     Sex   Age  \\\n",
       " 0         3                            Braund, Mr. Owen Harris    male  22.0   \n",
       " 1         1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       " 2         3                             Heikkinen, Miss. Laina  female  26.0   \n",
       " 3         1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       " 4         3                           Allen, Mr. William Henry    male  35.0   \n",
       " ..      ...                                                ...     ...   ...   \n",
       " 886       2                              Montvila, Rev. Juozas    male  27.0   \n",
       " 887       1                       Graham, Miss. Margaret Edith  female  19.0   \n",
       " 888       3           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN   \n",
       " 889       1                              Behr, Mr. Karl Howell    male  26.0   \n",
       " 890       3                                Dooley, Mr. Patrick    male  32.0   \n",
       " \n",
       "      SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       " 0        1      0         A/5 21171   7.2500   NaN        S  \n",
       " 1        1      0          PC 17599  71.2833   C85        C  \n",
       " 2        0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       " 3        1      0            113803  53.1000  C123        S  \n",
       " 4        0      0            373450   8.0500   NaN        S  \n",
       " ..     ...    ...               ...      ...   ...      ...  \n",
       " 886      0      0            211536  13.0000   NaN        S  \n",
       " 887      0      0            112053  30.0000   B42        S  \n",
       " 888      1      2        W./C. 6607  23.4500   NaN        S  \n",
       " 889      0      0            111369  30.0000  C148        C  \n",
       " 890      0      0            370376   7.7500   NaN        Q  \n",
       " \n",
       " [889 rows x 10 columns],\n",
       " 0      0\n",
       " 1      1\n",
       " 2      1\n",
       " 3      1\n",
       " 4      0\n",
       "       ..\n",
       " 886    0\n",
       " 887    1\n",
       " 888    0\n",
       " 889    1\n",
       " 890    0\n",
       " Name: Survived, Length: 889, dtype: int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data',\n",
      " 'description',\n",
      " 'mlmodel',\n",
      " 'prepare_data__memory',\n",
      " 'prepare_data__steps',\n",
      " 'prepare_data__verbose',\n",
      " 'prepare_data__nan_drpr',\n",
      " 'prepare_data__nan_drpr__key',\n",
      " 'prepare_data',\n",
      " 'preprocess_data',\n",
      " 'ycol',\n",
      " 'preprocessing',\n",
      " 'train',\n",
      " 'preprocessing__n_jobs',\n",
      " 'preprocessing__remainder',\n",
      " 'preprocessing__sparse_threshold',\n",
      " 'preprocessing__transformer_weights',\n",
      " 'preprocessing__transformers',\n",
      " 'preprocessing__verbose',\n",
      " 'preprocessing__enc',\n",
      " 'preprocessing__imp_scaler',\n",
      " 'preprocessing__pre_Name',\n",
      " 'preprocessing__pre_Cabin',\n",
      " 'preprocessing__pre_Ticket',\n",
      " 'preprocessing__Pre_SibSp',\n",
      " 'preprocessing__Pre_Parch',\n",
      " 'preprocessing__enc__categories',\n",
      " 'preprocessing__enc__drop',\n",
      " 'preprocessing__enc__dtype',\n",
      " 'preprocessing__enc__handle_unknown',\n",
      " 'preprocessing__enc__sparse',\n",
      " 'preprocessing__imp_scaler__memory',\n",
      " 'preprocessing__imp_scaler__steps',\n",
      " 'preprocessing__imp_scaler__verbose',\n",
      " 'preprocessing__imp_scaler__imp',\n",
      " 'preprocessing__imp_scaler__scaler',\n",
      " 'preprocessing__imp_scaler__imp__add_indicator',\n",
      " 'preprocessing__imp_scaler__imp__copy',\n",
      " 'preprocessing__imp_scaler__imp__fill_value',\n",
      " 'preprocessing__imp_scaler__imp__missing_values',\n",
      " 'preprocessing__imp_scaler__imp__strategy',\n",
      " 'preprocessing__imp_scaler__imp__verbose',\n",
      " 'preprocessing__imp_scaler__scaler__copy',\n",
      " 'preprocessing__imp_scaler__scaler__with_mean',\n",
      " 'preprocessing__imp_scaler__scaler__with_std',\n",
      " 'preprocessing__pre_Name__memory',\n",
      " 'preprocessing__pre_Name__steps',\n",
      " 'preprocessing__pre_Name__verbose',\n",
      " 'preprocessing__pre_Name__featurize',\n",
      " 'preprocessing__pre_Name__enc',\n",
      " 'preprocessing__pre_Name__featurize__accept_sparse',\n",
      " 'preprocessing__pre_Name__featurize__check_inverse',\n",
      " 'preprocessing__pre_Name__featurize__func',\n",
      " 'preprocessing__pre_Name__featurize__inv_kw_args',\n",
      " 'preprocessing__pre_Name__featurize__inverse_func',\n",
      " 'preprocessing__pre_Name__featurize__kw_args',\n",
      " 'preprocessing__pre_Name__featurize__validate',\n",
      " 'preprocessing__pre_Name__enc__categories',\n",
      " 'preprocessing__pre_Name__enc__drop',\n",
      " 'preprocessing__pre_Name__enc__dtype',\n",
      " 'preprocessing__pre_Name__enc__handle_unknown',\n",
      " 'preprocessing__pre_Name__enc__sparse',\n",
      " 'preprocessing__pre_Cabin__memory',\n",
      " 'preprocessing__pre_Cabin__steps',\n",
      " 'preprocessing__pre_Cabin__verbose',\n",
      " 'preprocessing__pre_Cabin__featurize',\n",
      " 'preprocessing__pre_Cabin__enc',\n",
      " 'preprocessing__pre_Cabin__featurize__accept_sparse',\n",
      " 'preprocessing__pre_Cabin__featurize__check_inverse',\n",
      " 'preprocessing__pre_Cabin__featurize__func',\n",
      " 'preprocessing__pre_Cabin__featurize__inv_kw_args',\n",
      " 'preprocessing__pre_Cabin__featurize__inverse_func',\n",
      " 'preprocessing__pre_Cabin__featurize__kw_args',\n",
      " 'preprocessing__pre_Cabin__featurize__validate',\n",
      " 'preprocessing__pre_Cabin__enc__categories',\n",
      " 'preprocessing__pre_Cabin__enc__drop',\n",
      " 'preprocessing__pre_Cabin__enc__dtype',\n",
      " 'preprocessing__pre_Cabin__enc__handle_unknown',\n",
      " 'preprocessing__pre_Cabin__enc__sparse',\n",
      " 'preprocessing__pre_Ticket__memory',\n",
      " 'preprocessing__pre_Ticket__steps',\n",
      " 'preprocessing__pre_Ticket__verbose',\n",
      " 'preprocessing__pre_Ticket__featurize',\n",
      " 'preprocessing__pre_Ticket__binarizer',\n",
      " 'preprocessing__pre_Ticket__featurize__accept_sparse',\n",
      " 'preprocessing__pre_Ticket__featurize__check_inverse',\n",
      " 'preprocessing__pre_Ticket__featurize__func',\n",
      " 'preprocessing__pre_Ticket__featurize__inv_kw_args',\n",
      " 'preprocessing__pre_Ticket__featurize__inverse_func',\n",
      " 'preprocessing__pre_Ticket__featurize__kw_args',\n",
      " 'preprocessing__pre_Ticket__featurize__validate',\n",
      " 'preprocessing__pre_Ticket__binarizer__accept_sparse',\n",
      " 'preprocessing__pre_Ticket__binarizer__check_inverse',\n",
      " 'preprocessing__pre_Ticket__binarizer__func',\n",
      " 'preprocessing__pre_Ticket__binarizer__inv_kw_args',\n",
      " 'preprocessing__pre_Ticket__binarizer__inverse_func',\n",
      " 'preprocessing__pre_Ticket__binarizer__kw_args',\n",
      " 'preprocessing__pre_Ticket__binarizer__validate',\n",
      " 'preprocessing__Pre_SibSp__memory',\n",
      " 'preprocessing__Pre_SibSp__steps',\n",
      " 'preprocessing__Pre_SibSp__verbose',\n",
      " 'preprocessing__Pre_SibSp__binner',\n",
      " 'preprocessing__Pre_SibSp__enc',\n",
      " 'preprocessing__Pre_SibSp__binner__accept_sparse',\n",
      " 'preprocessing__Pre_SibSp__binner__check_inverse',\n",
      " 'preprocessing__Pre_SibSp__binner__func',\n",
      " 'preprocessing__Pre_SibSp__binner__inv_kw_args',\n",
      " 'preprocessing__Pre_SibSp__binner__inverse_func',\n",
      " 'preprocessing__Pre_SibSp__binner__kw_args',\n",
      " 'preprocessing__Pre_SibSp__binner__validate',\n",
      " 'preprocessing__Pre_SibSp__enc__categories',\n",
      " 'preprocessing__Pre_SibSp__enc__drop',\n",
      " 'preprocessing__Pre_SibSp__enc__dtype',\n",
      " 'preprocessing__Pre_SibSp__enc__handle_unknown',\n",
      " 'preprocessing__Pre_SibSp__enc__sparse',\n",
      " 'preprocessing__Pre_Parch__memory',\n",
      " 'preprocessing__Pre_Parch__steps',\n",
      " 'preprocessing__Pre_Parch__verbose',\n",
      " 'preprocessing__Pre_Parch__binner',\n",
      " 'preprocessing__Pre_Parch__enc',\n",
      " 'preprocessing__Pre_Parch__binner__accept_sparse',\n",
      " 'preprocessing__Pre_Parch__binner__check_inverse',\n",
      " 'preprocessing__Pre_Parch__binner__func',\n",
      " 'preprocessing__Pre_Parch__binner__inv_kw_args',\n",
      " 'preprocessing__Pre_Parch__binner__inverse_func',\n",
      " 'preprocessing__Pre_Parch__binner__kw_args',\n",
      " 'preprocessing__Pre_Parch__binner__validate',\n",
      " 'preprocessing__Pre_Parch__enc__categories',\n",
      " 'preprocessing__Pre_Parch__enc__drop',\n",
      " 'preprocessing__Pre_Parch__enc__dtype',\n",
      " 'preprocessing__Pre_Parch__enc__handle_unknown',\n",
      " 'preprocessing__Pre_Parch__enc__sparse',\n",
      " 'train__bootstrap',\n",
      " 'train__ccp_alpha',\n",
      " 'train__class_weight',\n",
      " 'train__criterion',\n",
      " 'train__max_depth',\n",
      " 'train__max_features',\n",
      " 'train__max_leaf_nodes',\n",
      " 'train__max_samples',\n",
      " 'train__min_impurity_decrease',\n",
      " 'train__min_impurity_split',\n",
      " 'train__min_samples_leaf',\n",
      " 'train__min_samples_split',\n",
      " 'train__min_weight_fraction_leaf',\n",
      " 'train__n_estimators',\n",
      " 'train__n_jobs',\n",
      " 'train__oob_score',\n",
      " 'train__random_state',\n",
      " 'train__verbose',\n",
      " 'train__warm_start']\n"
     ]
    }
   ],
   "source": [
    "print_params(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataPipeline"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX, dfy = dp.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9910011248593926"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataPipeline"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9910011248593926"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.score(dfX, dfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81460674, 0.79213483, 0.84269663, 0.74719101, 0.84180791])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(dp, dfX, dfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80337079, 0.79775281, 0.85955056, 0.73595506, 0.84180791])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = dp.get_pipeline()\n",
    "cross_val_score(pipe, dfX, dfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.data = df.loc[1:100, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "DataPipelineNotFittedError",
     "evalue": "Please fit the data first using the fit method!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataPipelineNotFittedError\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-3d2d99b72765>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/main/coding/Python-code/mygit/Titanic-Survival/titansurv/pipeline/data_pipeline.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, *args, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_dp_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train_score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/main/coding/Python-code/mygit/Titanic-Survival/titansurv/pipeline/data_pipeline.py\u001b[0m in \u001b[0;36m_check_dp_is_fitted\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_dp_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_fitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mDataPipelineNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please fit the data first using the fit method!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataPipelineNotFittedError\u001b[0m: Please fit the data first using the fit method!"
     ]
    }
   ],
   "source": [
    "dp.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX, dfy = dp.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessing',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('enc',\n",
       "                                                  OneHotEncoder(categories='auto',\n",
       "                                                                drop='first',\n",
       "                                                                dtype=<class 'numpy.float64'>,\n",
       "                                                                handle_unknown='error',\n",
       "                                                                sparse=True),\n",
       "                                                  ['Sex', 'Embarked']),\n",
       "                                                 ('imp_scaler',\n",
       "                                                  Pipeline(memory='passthrough',\n",
       "                                                           steps=[('i...\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=None, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = dp.get_pipeline()\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The following were the preprocessing steps used: \n",
       "1. **Embarked**: Dropped NA rows and applied OneHotEncoding\n",
       "2. **Age** : Applied Mean Imputation and Mean Normalization\n",
       "3. **Fare**: Mean Normalization\n",
       "4. **Sex**: OneHotEncoding\n",
       "5. **Name**: Categorised into ['Mr', 'Mrs', 'Miss', 'Master', 'Special']<br/> \n",
       "    5.1 Rename [Mlle, Ms] -> Miss      \n",
       "    5.2 Rename [Mme] -> Mrs     \n",
       "    5.3 Put the Rest -> Special     \n",
       "    Then performed OneHotEncoding\n",
       "6. **Ticket** categorized into [1: numeric, 0: else] <br/>\n",
       "    6.1 Remove special characters but not space <br/>\n",
       "    6.2 Replace numeric strings by 'numeric' <br/>\n",
       "    6.3 Split on space and keep the first item <br/>\n",
       " Then applied binarizer for [1: numeric, 0: else]\n",
       "7. **SibSp** binned into [0, 1, >1] and applied OneHotEncoding\n",
       "8. **Parch** binned into [0, 1, >1] and applied OneHotEncoding\n",
       "\n",
       "Tuned ML model: **RandomForestClassifier** using GridSearchCV"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dp.get_description(markdown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "DataPipelineNotFittedError",
     "evalue": "Please fit the data first using the fit method!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataPipelineNotFittedError\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-3d2d99b72765>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/main/coding/Python-code/mygit/Titanic-Survival/titansurv/pipeline/data_pipeline.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, *args, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_dp_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train_score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/main/coding/Python-code/mygit/Titanic-Survival/titansurv/pipeline/data_pipeline.py\u001b[0m in \u001b[0;36m_check_dp_is_fitted\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_dp_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_fitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mDataPipelineNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please fit the data first using the fit method!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataPipelineNotFittedError\u001b[0m: Please fit the data first using the fit method!"
     ]
    }
   ],
   "source": [
    "dp.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from titansurv.pipeline import pipeline1 as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The following were the preprocessing steps used: \n",
       "1. **Embarked**: Dropped NA rows and applied OneHotEncoding\n",
       "2. **Age** : Applied Mean Imputation and Mean Normalization\n",
       "3. **Fare**: Mean Normalization\n",
       "4. **Sex**: OneHotEncoding\n",
       "5. **Name**: Categorised into ['Mr', 'Mrs', 'Miss', 'Master', 'Special']<br/> \n",
       "    5.1 Rename [Mlle, Ms] -> Miss      \n",
       "    5.2 Rename [Mme] -> Mrs     \n",
       "    5.3 Put the Rest -> Special     \n",
       "    Then performed OneHotEncoding\n",
       "6. **Ticket** categorized into [1: numeric, 0: else] <br/>\n",
       "    6.1 Remove special characters but not space <br/>\n",
       "    6.2 Replace numeric strings by 'numeric' <br/>\n",
       "    6.3 Split on space and keep the first item <br/>\n",
       " Then applied binarizer for [1: numeric, 0: else]\n",
       "7. **SibSp** binned into [0, 1, >1] and applied OneHotEncoding\n",
       "8. **Parch** binned into [0, 1, >1] and applied OneHotEncoding\n",
       "\n",
       "Tuned ML model: **RandomForestClassifier** using GridSearchCV"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dp.get_description(markdown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.set_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data',\n",
      " 'description',\n",
      " 'mlmodel',\n",
      " 'prepare_data__memory',\n",
      " 'prepare_data__steps',\n",
      " 'prepare_data__verbose',\n",
      " 'prepare_data__nan_drpr',\n",
      " 'prepare_data__nan_drpr__key',\n",
      " 'prepare_data',\n",
      " 'preprocess_data',\n",
      " 'ycol',\n",
      " 'preprocessing',\n",
      " 'train',\n",
      " 'preprocessing__n_jobs',\n",
      " 'preprocessing__remainder',\n",
      " 'preprocessing__sparse_threshold',\n",
      " 'preprocessing__transformer_weights',\n",
      " 'preprocessing__transformers',\n",
      " 'preprocessing__verbose',\n",
      " 'preprocessing__enc',\n",
      " 'preprocessing__imp_scaler',\n",
      " 'preprocessing__scaler',\n",
      " 'preprocessing__pre_Name',\n",
      " 'preprocessing__pre_Cabin',\n",
      " 'preprocessing__pre_Ticket',\n",
      " 'preprocessing__Pre_SibSp',\n",
      " 'preprocessing__Pre_Parch',\n",
      " 'preprocessing__enc__categories',\n",
      " 'preprocessing__enc__drop',\n",
      " 'preprocessing__enc__dtype',\n",
      " 'preprocessing__enc__handle_unknown',\n",
      " 'preprocessing__enc__sparse',\n",
      " 'preprocessing__imp_scaler__memory',\n",
      " 'preprocessing__imp_scaler__steps',\n",
      " 'preprocessing__imp_scaler__verbose',\n",
      " 'preprocessing__imp_scaler__imp',\n",
      " 'preprocessing__imp_scaler__scaler',\n",
      " 'preprocessing__imp_scaler__imp__add_indicator',\n",
      " 'preprocessing__imp_scaler__imp__copy',\n",
      " 'preprocessing__imp_scaler__imp__fill_value',\n",
      " 'preprocessing__imp_scaler__imp__missing_values',\n",
      " 'preprocessing__imp_scaler__imp__strategy',\n",
      " 'preprocessing__imp_scaler__imp__verbose',\n",
      " 'preprocessing__imp_scaler__scaler__copy',\n",
      " 'preprocessing__imp_scaler__scaler__with_mean',\n",
      " 'preprocessing__imp_scaler__scaler__with_std',\n",
      " 'preprocessing__scaler__copy',\n",
      " 'preprocessing__scaler__with_mean',\n",
      " 'preprocessing__scaler__with_std',\n",
      " 'preprocessing__pre_Name__memory',\n",
      " 'preprocessing__pre_Name__steps',\n",
      " 'preprocessing__pre_Name__verbose',\n",
      " 'preprocessing__pre_Name__featurize',\n",
      " 'preprocessing__pre_Name__enc',\n",
      " 'preprocessing__pre_Name__featurize__accept_sparse',\n",
      " 'preprocessing__pre_Name__featurize__check_inverse',\n",
      " 'preprocessing__pre_Name__featurize__func',\n",
      " 'preprocessing__pre_Name__featurize__inv_kw_args',\n",
      " 'preprocessing__pre_Name__featurize__inverse_func',\n",
      " 'preprocessing__pre_Name__featurize__kw_args',\n",
      " 'preprocessing__pre_Name__featurize__validate',\n",
      " 'preprocessing__pre_Name__enc__categories',\n",
      " 'preprocessing__pre_Name__enc__drop',\n",
      " 'preprocessing__pre_Name__enc__dtype',\n",
      " 'preprocessing__pre_Name__enc__handle_unknown',\n",
      " 'preprocessing__pre_Name__enc__sparse',\n",
      " 'preprocessing__pre_Cabin__memory',\n",
      " 'preprocessing__pre_Cabin__steps',\n",
      " 'preprocessing__pre_Cabin__verbose',\n",
      " 'preprocessing__pre_Cabin__featurize',\n",
      " 'preprocessing__pre_Cabin__enc',\n",
      " 'preprocessing__pre_Cabin__featurize__accept_sparse',\n",
      " 'preprocessing__pre_Cabin__featurize__check_inverse',\n",
      " 'preprocessing__pre_Cabin__featurize__func',\n",
      " 'preprocessing__pre_Cabin__featurize__inv_kw_args',\n",
      " 'preprocessing__pre_Cabin__featurize__inverse_func',\n",
      " 'preprocessing__pre_Cabin__featurize__kw_args',\n",
      " 'preprocessing__pre_Cabin__featurize__validate',\n",
      " 'preprocessing__pre_Cabin__enc__categories',\n",
      " 'preprocessing__pre_Cabin__enc__drop',\n",
      " 'preprocessing__pre_Cabin__enc__dtype',\n",
      " 'preprocessing__pre_Cabin__enc__handle_unknown',\n",
      " 'preprocessing__pre_Cabin__enc__sparse',\n",
      " 'preprocessing__pre_Ticket__memory',\n",
      " 'preprocessing__pre_Ticket__steps',\n",
      " 'preprocessing__pre_Ticket__verbose',\n",
      " 'preprocessing__pre_Ticket__featurize',\n",
      " 'preprocessing__pre_Ticket__binarizer',\n",
      " 'preprocessing__pre_Ticket__featurize__accept_sparse',\n",
      " 'preprocessing__pre_Ticket__featurize__check_inverse',\n",
      " 'preprocessing__pre_Ticket__featurize__func',\n",
      " 'preprocessing__pre_Ticket__featurize__inv_kw_args',\n",
      " 'preprocessing__pre_Ticket__featurize__inverse_func',\n",
      " 'preprocessing__pre_Ticket__featurize__kw_args',\n",
      " 'preprocessing__pre_Ticket__featurize__validate',\n",
      " 'preprocessing__pre_Ticket__binarizer__accept_sparse',\n",
      " 'preprocessing__pre_Ticket__binarizer__check_inverse',\n",
      " 'preprocessing__pre_Ticket__binarizer__func',\n",
      " 'preprocessing__pre_Ticket__binarizer__inv_kw_args',\n",
      " 'preprocessing__pre_Ticket__binarizer__inverse_func',\n",
      " 'preprocessing__pre_Ticket__binarizer__kw_args',\n",
      " 'preprocessing__pre_Ticket__binarizer__validate',\n",
      " 'preprocessing__Pre_SibSp__memory',\n",
      " 'preprocessing__Pre_SibSp__steps',\n",
      " 'preprocessing__Pre_SibSp__verbose',\n",
      " 'preprocessing__Pre_SibSp__binner',\n",
      " 'preprocessing__Pre_SibSp__enc',\n",
      " 'preprocessing__Pre_SibSp__binner__accept_sparse',\n",
      " 'preprocessing__Pre_SibSp__binner__check_inverse',\n",
      " 'preprocessing__Pre_SibSp__binner__func',\n",
      " 'preprocessing__Pre_SibSp__binner__inv_kw_args',\n",
      " 'preprocessing__Pre_SibSp__binner__inverse_func',\n",
      " 'preprocessing__Pre_SibSp__binner__kw_args',\n",
      " 'preprocessing__Pre_SibSp__binner__validate',\n",
      " 'preprocessing__Pre_SibSp__enc__categories',\n",
      " 'preprocessing__Pre_SibSp__enc__drop',\n",
      " 'preprocessing__Pre_SibSp__enc__dtype',\n",
      " 'preprocessing__Pre_SibSp__enc__handle_unknown',\n",
      " 'preprocessing__Pre_SibSp__enc__sparse',\n",
      " 'preprocessing__Pre_Parch__memory',\n",
      " 'preprocessing__Pre_Parch__steps',\n",
      " 'preprocessing__Pre_Parch__verbose',\n",
      " 'preprocessing__Pre_Parch__binner',\n",
      " 'preprocessing__Pre_Parch__enc',\n",
      " 'preprocessing__Pre_Parch__binner__accept_sparse',\n",
      " 'preprocessing__Pre_Parch__binner__check_inverse',\n",
      " 'preprocessing__Pre_Parch__binner__func',\n",
      " 'preprocessing__Pre_Parch__binner__inv_kw_args',\n",
      " 'preprocessing__Pre_Parch__binner__inverse_func',\n",
      " 'preprocessing__Pre_Parch__binner__kw_args',\n",
      " 'preprocessing__Pre_Parch__binner__validate',\n",
      " 'preprocessing__Pre_Parch__enc__categories',\n",
      " 'preprocessing__Pre_Parch__enc__drop',\n",
      " 'preprocessing__Pre_Parch__enc__dtype',\n",
      " 'preprocessing__Pre_Parch__enc__handle_unknown',\n",
      " 'preprocessing__Pre_Parch__enc__sparse',\n",
      " 'train__bootstrap',\n",
      " 'train__ccp_alpha',\n",
      " 'train__class_weight',\n",
      " 'train__criterion',\n",
      " 'train__max_depth',\n",
      " 'train__max_features',\n",
      " 'train__max_leaf_nodes',\n",
      " 'train__max_samples',\n",
      " 'train__min_impurity_decrease',\n",
      " 'train__min_impurity_split',\n",
      " 'train__min_samples_leaf',\n",
      " 'train__min_samples_split',\n",
      " 'train__min_weight_fraction_leaf',\n",
      " 'train__n_estimators',\n",
      " 'train__n_jobs',\n",
      " 'train__oob_score',\n",
      " 'train__random_state',\n",
      " 'train__verbose',\n",
      " 'train__warm_start']\n"
     ]
    }
   ],
   "source": [
    "from titansurv.pipeline import pipeline1 as dp\n",
    "from titansurv.utils import print_params\n",
    "print_params(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data',\n",
      " 'description',\n",
      " 'mlmodel',\n",
      " 'prepare_data__memory',\n",
      " 'prepare_data__steps',\n",
      " 'prepare_data__verbose',\n",
      " 'prepare_data__nan_drpr',\n",
      " 'prepare_data__nan_drpr__key',\n",
      " 'prepare_data',\n",
      " 'preprocess_data',\n",
      " 'ycol',\n",
      " 'preprocessing',\n",
      " 'train',\n",
      " 'preprocessing__n_jobs',\n",
      " 'preprocessing__remainder',\n",
      " 'preprocessing__sparse_threshold',\n",
      " 'preprocessing__transformer_weights',\n",
      " 'preprocessing__transformers',\n",
      " 'preprocessing__verbose',\n",
      " 'preprocessing__enc',\n",
      " 'preprocessing__imp_scaler',\n",
      " 'preprocessing__scaler',\n",
      " 'preprocessing__pre_Name',\n",
      " 'preprocessing__pre_Cabin',\n",
      " 'preprocessing__pre_Ticket',\n",
      " 'preprocessing__Pre_SibSp',\n",
      " 'preprocessing__Pre_Parch',\n",
      " 'preprocessing__enc__categories',\n",
      " 'preprocessing__enc__drop',\n",
      " 'preprocessing__enc__dtype',\n",
      " 'preprocessing__enc__handle_unknown',\n",
      " 'preprocessing__enc__sparse',\n",
      " 'preprocessing__imp_scaler__memory',\n",
      " 'preprocessing__imp_scaler__steps',\n",
      " 'preprocessing__imp_scaler__verbose',\n",
      " 'preprocessing__imp_scaler__imp',\n",
      " 'preprocessing__imp_scaler__scaler',\n",
      " 'preprocessing__imp_scaler__imp__add_indicator',\n",
      " 'preprocessing__imp_scaler__imp__copy',\n",
      " 'preprocessing__imp_scaler__imp__fill_value',\n",
      " 'preprocessing__imp_scaler__imp__missing_values',\n",
      " 'preprocessing__imp_scaler__imp__strategy',\n",
      " 'preprocessing__imp_scaler__imp__verbose',\n",
      " 'preprocessing__imp_scaler__scaler__copy',\n",
      " 'preprocessing__imp_scaler__scaler__with_mean',\n",
      " 'preprocessing__imp_scaler__scaler__with_std',\n",
      " 'preprocessing__scaler__copy',\n",
      " 'preprocessing__scaler__with_mean',\n",
      " 'preprocessing__scaler__with_std',\n",
      " 'preprocessing__pre_Name__memory',\n",
      " 'preprocessing__pre_Name__steps',\n",
      " 'preprocessing__pre_Name__verbose',\n",
      " 'preprocessing__pre_Name__featurize',\n",
      " 'preprocessing__pre_Name__enc',\n",
      " 'preprocessing__pre_Name__featurize__accept_sparse',\n",
      " 'preprocessing__pre_Name__featurize__check_inverse',\n",
      " 'preprocessing__pre_Name__featurize__func',\n",
      " 'preprocessing__pre_Name__featurize__inv_kw_args',\n",
      " 'preprocessing__pre_Name__featurize__inverse_func',\n",
      " 'preprocessing__pre_Name__featurize__kw_args',\n",
      " 'preprocessing__pre_Name__featurize__validate',\n",
      " 'preprocessing__pre_Name__enc__categories',\n",
      " 'preprocessing__pre_Name__enc__drop',\n",
      " 'preprocessing__pre_Name__enc__dtype',\n",
      " 'preprocessing__pre_Name__enc__handle_unknown',\n",
      " 'preprocessing__pre_Name__enc__sparse',\n",
      " 'preprocessing__pre_Cabin__memory',\n",
      " 'preprocessing__pre_Cabin__steps',\n",
      " 'preprocessing__pre_Cabin__verbose',\n",
      " 'preprocessing__pre_Cabin__featurize',\n",
      " 'preprocessing__pre_Cabin__enc',\n",
      " 'preprocessing__pre_Cabin__featurize__accept_sparse',\n",
      " 'preprocessing__pre_Cabin__featurize__check_inverse',\n",
      " 'preprocessing__pre_Cabin__featurize__func',\n",
      " 'preprocessing__pre_Cabin__featurize__inv_kw_args',\n",
      " 'preprocessing__pre_Cabin__featurize__inverse_func',\n",
      " 'preprocessing__pre_Cabin__featurize__kw_args',\n",
      " 'preprocessing__pre_Cabin__featurize__validate',\n",
      " 'preprocessing__pre_Cabin__enc__categories',\n",
      " 'preprocessing__pre_Cabin__enc__drop',\n",
      " 'preprocessing__pre_Cabin__enc__dtype',\n",
      " 'preprocessing__pre_Cabin__enc__handle_unknown',\n",
      " 'preprocessing__pre_Cabin__enc__sparse',\n",
      " 'preprocessing__pre_Ticket__memory',\n",
      " 'preprocessing__pre_Ticket__steps',\n",
      " 'preprocessing__pre_Ticket__verbose',\n",
      " 'preprocessing__pre_Ticket__featurize',\n",
      " 'preprocessing__pre_Ticket__binarizer',\n",
      " 'preprocessing__pre_Ticket__featurize__accept_sparse',\n",
      " 'preprocessing__pre_Ticket__featurize__check_inverse',\n",
      " 'preprocessing__pre_Ticket__featurize__func',\n",
      " 'preprocessing__pre_Ticket__featurize__inv_kw_args',\n",
      " 'preprocessing__pre_Ticket__featurize__inverse_func',\n",
      " 'preprocessing__pre_Ticket__featurize__kw_args',\n",
      " 'preprocessing__pre_Ticket__featurize__validate',\n",
      " 'preprocessing__pre_Ticket__binarizer__accept_sparse',\n",
      " 'preprocessing__pre_Ticket__binarizer__check_inverse',\n",
      " 'preprocessing__pre_Ticket__binarizer__func',\n",
      " 'preprocessing__pre_Ticket__binarizer__inv_kw_args',\n",
      " 'preprocessing__pre_Ticket__binarizer__inverse_func',\n",
      " 'preprocessing__pre_Ticket__binarizer__kw_args',\n",
      " 'preprocessing__pre_Ticket__binarizer__validate',\n",
      " 'preprocessing__Pre_SibSp__memory',\n",
      " 'preprocessing__Pre_SibSp__steps',\n",
      " 'preprocessing__Pre_SibSp__verbose',\n",
      " 'preprocessing__Pre_SibSp__binner',\n",
      " 'preprocessing__Pre_SibSp__enc',\n",
      " 'preprocessing__Pre_SibSp__binner__accept_sparse',\n",
      " 'preprocessing__Pre_SibSp__binner__check_inverse',\n",
      " 'preprocessing__Pre_SibSp__binner__func',\n",
      " 'preprocessing__Pre_SibSp__binner__inv_kw_args',\n",
      " 'preprocessing__Pre_SibSp__binner__inverse_func',\n",
      " 'preprocessing__Pre_SibSp__binner__kw_args',\n",
      " 'preprocessing__Pre_SibSp__binner__validate',\n",
      " 'preprocessing__Pre_SibSp__enc__categories',\n",
      " 'preprocessing__Pre_SibSp__enc__drop',\n",
      " 'preprocessing__Pre_SibSp__enc__dtype',\n",
      " 'preprocessing__Pre_SibSp__enc__handle_unknown',\n",
      " 'preprocessing__Pre_SibSp__enc__sparse',\n",
      " 'preprocessing__Pre_Parch__memory',\n",
      " 'preprocessing__Pre_Parch__steps',\n",
      " 'preprocessing__Pre_Parch__verbose',\n",
      " 'preprocessing__Pre_Parch__binner',\n",
      " 'preprocessing__Pre_Parch__enc',\n",
      " 'preprocessing__Pre_Parch__binner__accept_sparse',\n",
      " 'preprocessing__Pre_Parch__binner__check_inverse',\n",
      " 'preprocessing__Pre_Parch__binner__func',\n",
      " 'preprocessing__Pre_Parch__binner__inv_kw_args',\n",
      " 'preprocessing__Pre_Parch__binner__inverse_func',\n",
      " 'preprocessing__Pre_Parch__binner__kw_args',\n",
      " 'preprocessing__Pre_Parch__binner__validate',\n",
      " 'preprocessing__Pre_Parch__enc__categories',\n",
      " 'preprocessing__Pre_Parch__enc__drop',\n",
      " 'preprocessing__Pre_Parch__enc__dtype',\n",
      " 'preprocessing__Pre_Parch__enc__handle_unknown',\n",
      " 'preprocessing__Pre_Parch__enc__sparse',\n",
      " 'train__bootstrap',\n",
      " 'train__ccp_alpha',\n",
      " 'train__class_weight',\n",
      " 'train__criterion',\n",
      " 'train__max_depth',\n",
      " 'train__max_features',\n",
      " 'train__max_leaf_nodes',\n",
      " 'train__max_samples',\n",
      " 'train__min_impurity_decrease',\n",
      " 'train__min_impurity_split',\n",
      " 'train__min_samples_leaf',\n",
      " 'train__min_samples_split',\n",
      " 'train__min_weight_fraction_leaf',\n",
      " 'train__n_estimators',\n",
      " 'train__n_jobs',\n",
      " 'train__oob_score',\n",
      " 'train__random_state',\n",
      " 'train__verbose',\n",
      " 'train__warm_start']\n"
     ]
    }
   ],
   "source": [
    "print_params(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'train': [RidgeClassifier()],\n",
    "                         'train__alpha' :[0.1, 1, 10]},\n",
    "              {'train': [RandomForestClassifier()],\n",
    "               'train__n_estimators': [100]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             ('estimator', DataPipeline),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'train': [RidgeClassifier(alpha=1, class_weight=None,\n",
       "                                                    copy_X=True,\n",
       "                                                    fit_intercept=True,\n",
       "                                                    max_iter=None,\n",
       "                                                    normalize=False,\n",
       "                                                    random_state=None,\n",
       "                                                    solver='auto', tol=0.001)],\n",
       "                          'train__alpha': [0.1, 1, 10]},\n",
       "                         {'train': [RandomForestClassifier(bootstrap=True,\n",
       "                                                           ccp_alpha=0.0,\n",
       "                                                           cl...\n",
       "                                                           max_leaf_nodes=None,\n",
       "                                                           max_samples=None,\n",
       "                                                           min_impurity_decrease=0.0,\n",
       "                                                           min_impurity_split=None,\n",
       "                                                           min_samples_leaf=1,\n",
       "                                                           min_samples_split=2,\n",
       "                                                           min_weight_fraction_leaf=0.0,\n",
       "                                                           n_estimators=100,\n",
       "                                                           n_jobs=None,\n",
       "                                                           oob_score=False,\n",
       "                                                           random_state=None,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False)],\n",
       "                          'train__n_estimators': [100]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(dp, param_grid, cv=5)\n",
    "grid.fit(dfX, dfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'train': [RidgeClassifier()],\n",
    "              'train__alpha' :[0.1, 1, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_train</th>\n",
       "      <th>param_train__alpha</th>\n",
       "      <th>param_train__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026156</td>\n",
       "      <td>0.002497</td>\n",
       "      <td>0.014082</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>RidgeClassifier(alpha=1, class_weight=None, co...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'train': RidgeClassifier(alpha=1, class_weigh...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.807895</td>\n",
       "      <td>0.058820</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023584</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.013164</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>RidgeClassifier(alpha=1, class_weight=None, co...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'train': RidgeClassifier(alpha=1, class_weigh...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.828421</td>\n",
       "      <td>0.039330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.023565</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.013080</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>RidgeClassifier(alpha=1, class_weight=None, co...</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'train': RidgeClassifier(alpha=1, class_weigh...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.808421</td>\n",
       "      <td>0.072689</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.123478</td>\n",
       "      <td>0.012897</td>\n",
       "      <td>0.019471</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>RandomForestClassifier(bootstrap=True, ccp_alp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>{'train': RandomForestClassifier(bootstrap=Tru...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.807895</td>\n",
       "      <td>0.066782</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.026156      0.002497         0.014082        0.001211   \n",
       "1       0.023584      0.000182         0.013164        0.000114   \n",
       "2       0.023565      0.000270         0.013080        0.000072   \n",
       "3       0.123478      0.012897         0.019471        0.001825   \n",
       "\n",
       "                                         param_train param_train__alpha  \\\n",
       "0  RidgeClassifier(alpha=1, class_weight=None, co...                0.1   \n",
       "1  RidgeClassifier(alpha=1, class_weight=None, co...                  1   \n",
       "2  RidgeClassifier(alpha=1, class_weight=None, co...                 10   \n",
       "3  RandomForestClassifier(bootstrap=True, ccp_alp...                NaN   \n",
       "\n",
       "  param_train__n_estimators  \\\n",
       "0                       NaN   \n",
       "1                       NaN   \n",
       "2                       NaN   \n",
       "3                       100   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'train': RidgeClassifier(alpha=1, class_weigh...               0.85   \n",
       "1  {'train': RidgeClassifier(alpha=1, class_weigh...               0.85   \n",
       "2  {'train': RidgeClassifier(alpha=1, class_weigh...               0.85   \n",
       "3  {'train': RandomForestClassifier(bootstrap=Tru...               0.85   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0               0.70               0.85               0.85           0.789474   \n",
       "1               0.75               0.85               0.85           0.842105   \n",
       "2               0.70               0.90               0.75           0.842105   \n",
       "3               0.70               0.90               0.80           0.789474   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.807895        0.058820                3  \n",
       "1         0.828421        0.039330                1  \n",
       "2         0.808421        0.072689                2  \n",
       "3         0.807895        0.066782                3  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(grid.cv_results_)\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_best = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataPipeline"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_train</th>\n",
       "      <th>param_train__alpha</th>\n",
       "      <th>param_train__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026156</td>\n",
       "      <td>0.002497</td>\n",
       "      <td>0.014082</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>RidgeClassifier(alpha=1, class_weight=None, co...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'train': RidgeClassifier(alpha=1, class_weigh...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.807895</td>\n",
       "      <td>0.058820</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023584</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.013164</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>RidgeClassifier(alpha=1, class_weight=None, co...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'train': RidgeClassifier(alpha=1, class_weigh...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.828421</td>\n",
       "      <td>0.039330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.023565</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.013080</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>RidgeClassifier(alpha=1, class_weight=None, co...</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'train': RidgeClassifier(alpha=1, class_weigh...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.808421</td>\n",
       "      <td>0.072689</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.123478</td>\n",
       "      <td>0.012897</td>\n",
       "      <td>0.019471</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>RandomForestClassifier(bootstrap=True, ccp_alp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>{'train': RandomForestClassifier(bootstrap=Tru...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.807895</td>\n",
       "      <td>0.066782</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.026156      0.002497         0.014082        0.001211   \n",
       "1       0.023584      0.000182         0.013164        0.000114   \n",
       "2       0.023565      0.000270         0.013080        0.000072   \n",
       "3       0.123478      0.012897         0.019471        0.001825   \n",
       "\n",
       "                                         param_train param_train__alpha  \\\n",
       "0  RidgeClassifier(alpha=1, class_weight=None, co...                0.1   \n",
       "1  RidgeClassifier(alpha=1, class_weight=None, co...                  1   \n",
       "2  RidgeClassifier(alpha=1, class_weight=None, co...                 10   \n",
       "3  RandomForestClassifier(bootstrap=True, ccp_alp...                NaN   \n",
       "\n",
       "  param_train__n_estimators  \\\n",
       "0                       NaN   \n",
       "1                       NaN   \n",
       "2                       NaN   \n",
       "3                       100   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'train': RidgeClassifier(alpha=1, class_weigh...               0.85   \n",
       "1  {'train': RidgeClassifier(alpha=1, class_weigh...               0.85   \n",
       "2  {'train': RidgeClassifier(alpha=1, class_weigh...               0.85   \n",
       "3  {'train': RandomForestClassifier(bootstrap=Tru...               0.85   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0               0.70               0.85               0.85           0.789474   \n",
       "1               0.75               0.85               0.85           0.842105   \n",
       "2               0.70               0.90               0.75           0.842105   \n",
       "3               0.70               0.90               0.80           0.789474   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.807895        0.058820                3  \n",
       "1         0.828421        0.039330                1  \n",
       "2         0.808421        0.072689                2  \n",
       "3         0.807895        0.066782                3  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:titansurv] *",
   "language": "python",
   "name": "conda-env-titansurv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
