{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../titansurv/pipeline/data_pipeline.py:37: UserWarning: Please set the data first using set_data method!\n",
      "  warnings.warn('Please set the data first using set_data method!')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import titansurv\n",
    "from titansurv.pipeline import DataPipeline\n",
    "from titansurv.preprocessing.transformers import NaNDropper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/raw/train.csv\").drop('PassengerId', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Name      891 non-null    object \n",
      " 3   Sex       891 non-null    object \n",
      " 4   Age       714 non-null    float64\n",
      " 5   SibSp     891 non-null    int64  \n",
      " 6   Parch     891 non-null    int64  \n",
      " 7   Ticket    891 non-null    object \n",
      " 8   Fare      891 non-null    float64\n",
      " 9   Cabin     204 non-null    object \n",
      " 10  Embarked  889 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 76.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following were the preprocessing steps used: \n",
    "1. **Embarked**: Dropped NA rows and applied OneHotEncoding\n",
    "2. **Age** : Applied Mean Imputation and Mean Normalization\n",
    "3. **Fare**: Mean Normalization\n",
    "4. **Sex**: OneHotEncoding\n",
    "5. **Name**: Categorised into ['Mr', 'Mrs', 'Miss', 'Master', 'Special']<br/> \n",
    "    5.1 Rename [Mlle, Ms] -> Miss      \n",
    "    5.2 Rename [Mme] -> Mrs     \n",
    "    5.3 Put the Rest -> Special     \n",
    "    Then performed OneHotEncoding\n",
    "6. **Ticket** categorized into [1: numeric, 0: else] <br/>\n",
    "    6.1 Remove special characters but not space <br/>\n",
    "    6.2 Replace numeric strings by 'numeric' <br/>\n",
    "    6.3 Split on space and keep the first item <br/>\n",
    " Then applied binarizer for [1: numeric, 0: else]\n",
    "7. **SibSp** binned into [0, 1, >1] and applied OneHotEncoding\n",
    "8. **Parch** binned into [0, 1, >1] and applied OneHotEncoding\n",
    "\n",
    "Tuned ML model: **RandomForestClassifier** using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = r'''The following were the preprocessing steps used: \n",
    "1. **Embarked**: Dropped NA rows and applied OneHotEncoding\n",
    "2. **Age** : Applied Mean Imputation and Mean Normalization\n",
    "3. **Fare**: Mean Normalization\n",
    "4. **Sex**: OneHotEncoding\n",
    "5. **Name**: Categorised into ['Mr', 'Mrs', 'Miss', 'Master', 'Special']<br/> \n",
    "    5.1 Rename [Mlle, Ms] -> Miss      \n",
    "    5.2 Rename [Mme] -> Mrs     \n",
    "    5.3 Put the Rest -> Special     \n",
    "    Then performed OneHotEncoding\n",
    "6. **Ticket** categorized into [1: numeric, 0: else] <br/>\n",
    "    6.1 Remove special characters but not space <br/>\n",
    "    6.2 Replace numeric strings by 'numeric' <br/>\n",
    "    6.3 Split on space and keep the first item <br/>\n",
    " Then applied binarizer for [1: numeric, 0: else]\n",
    "7. **SibSp** binned into [0, 1, >1] and applied OneHotEncoding\n",
    "8. **Parch** binned into [0, 1, >1] and applied OneHotEncoding\n",
    "\n",
    "Tuned ML model: **RandomForestClassifier** using GridSearchCV'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FE_SibSp(arr: np.array):\n",
    "    arr = arr.copy()\n",
    "    arr[arr>1] = 2\n",
    "    if len(arr.shape) == 1:\n",
    "        arr = arr.reshape(-1, 1)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def FE_Parch(arr: np.array):\n",
    "    arr = arr.copy()\n",
    "    arr[arr>1] = 2\n",
    "    if len(arr.shape) == 1:\n",
    "        arr = arr.reshape(-1, 1)\n",
    "    return arr\n",
    "\n",
    "def FE_Ticket(x):\n",
    "    x = x.str.replace(r'[^A-Za-z0-9\\s]+', '')\n",
    "    x = x.apply(lambda x: x.split(' ')[0] if not x.isdigit() else 'numeric')\n",
    "    \n",
    "    return x.values.reshape(-1, 1)\n",
    "\n",
    "def FE_Name(x, pattern='([A-Z][a-z]+)\\.'):\n",
    "    x = x.apply(lambda x: re.search(pattern, x).group(1))\n",
    "    x.replace(['Mlle', 'Ms'], 'Miss', inplace=True)\n",
    "    x.replace(['Mme'], 'Mrs', inplace=True)\n",
    "    x.loc[~x.isin(['Mr', 'Mrs', 'Miss', 'Master'])] = 'Special'\n",
    "    return x.values.reshape(-1, 1)\n",
    "\n",
    "\n",
    "def FE_Cabin(x):\n",
    "    col1 = x.str[0].fillna('NC')\n",
    "    return col1.values.reshape(-1, 1)\n",
    "\n",
    "@np.vectorize\n",
    "def binary_enc(x):\n",
    "    if x == 'numeric':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "binarizer = FunctionTransformer(binary_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data = Pipeline([\n",
    "    ('nan_drpr', NaNDropper(['Embarked']))\n",
    "])\n",
    "\n",
    "pre2 = Pipeline([\n",
    "    ('imp', SimpleImputer()),\n",
    "    ('scaler', StandardScaler())\n",
    "], 'passthrough')\n",
    "\n",
    "pre_Name = Pipeline([\n",
    "    ('featurize', FunctionTransformer(FE_Name)),\n",
    "    ('enc', OneHotEncoder(categories=[['Mr', 'Mrs', 'Miss', 'Master', 'Special']],\n",
    "                          drop='first'))\n",
    "])\n",
    "\n",
    "# TODO: Implement modify pipeline function for DRY\n",
    "pre_Cabin = Pipeline([\n",
    "    ('featurize', FunctionTransformer(FE_Cabin)),\n",
    "    ('enc', OneHotEncoder(categories=[['A', 'B', 'C', 'D', \n",
    "                                      'E', 'F', 'G', 'T', 'NC']], \n",
    "                          drop='first'))\n",
    "])\n",
    "\n",
    "pre_Ticket = Pipeline([\n",
    "    ('featurize', FunctionTransformer(FE_Ticket)),\n",
    "    ('binarizer', binarizer)\n",
    "])\n",
    "\n",
    "pre_SibSp = Pipeline([\n",
    "    ('binner', FunctionTransformer(FE_SibSp)),\n",
    "    ('enc', OneHotEncoder(drop='first'))\n",
    "])\n",
    "\n",
    "pre_Parch = Pipeline([\n",
    "    ('binner', FunctionTransformer(FE_Parch)),\n",
    "    ('enc', OneHotEncoder(drop='first'))\n",
    "])\n",
    "\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    ('enc', OneHotEncoder(drop='first'), ['Sex', 'Embarked']),\n",
    "    ('imp_scaler', pre2, ['Age', 'Fare']),\n",
    "    ('pre_Name', pre_Name, 'Name'),\n",
    "    ('pre_Cabin', pre_Cabin, 'Cabin'),\n",
    "    ('pre_Ticket', pre_Ticket, 'Ticket'),\n",
    "    ('Pre_SibSp', pre_SibSp, ['SibSp']),\n",
    "    ('Pre_Parch', pre_Parch, ['Parch'])\n",
    "], \n",
    "    'passthrough')\n",
    "\n",
    "mlmodel = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataPipeline(prepare_data, preprocess, mlmodel, df, 'Survived', description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "DataNotPreparedError",
     "evalue": "Please prepare the data first using the prepare method!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataNotPreparedError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-82b7eb90fc59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/main/coding/Python-code/mygit/Titanic-Survival/titansurv/pipeline/data_pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, *args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_dp_is_prepared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/main/coding/Python-code/mygit/Titanic-Survival/titansurv/pipeline/data_pipeline.py\u001b[0m in \u001b[0;36m_check_dp_is_prepared\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_dp_is_prepared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_prepared\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mDataNotPreparedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please prepare the data first using the prepare method!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_dp_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataNotPreparedError\u001b[0m: Please prepare the data first using the prepare method!"
     ]
    }
   ],
   "source": [
    "dp.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX, dfy = dp.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "DataPipelineNotFittedError",
     "evalue": "Please fit the data first using the fit method!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataPipelineNotFittedError\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3d2d99b72765>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/main/coding/Python-code/mygit/Titanic-Survival/titansurv/pipeline/data_pipeline.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_dp_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train_score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/main/coding/Python-code/mygit/Titanic-Survival/titansurv/pipeline/data_pipeline.py\u001b[0m in \u001b[0;36m_check_dp_is_fitted\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_dp_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_fitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mDataPipelineNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please fit the data first using the fit method!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataPipelineNotFittedError\u001b[0m: Please fit the data first using the fit method!"
     ]
    }
   ],
   "source": [
    "dp.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9910011248593926"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9910011248593926"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.score(dfX, dfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81460674, 0.79775281, 0.84269663, 0.74719101, 0.84745763])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(dp, dfX, dfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8258427 , 0.78651685, 0.87078652, 0.75280899, 0.83615819])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = dp.get_pipeline()\n",
    "cross_val_score(pipe, dfX, dfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.data = df.loc[1:100, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "DataPipelineNotFittedError",
     "evalue": "Please fit the data first using the fit method!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataPipelineNotFittedError\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-3d2d99b72765>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/main/coding/Python-code/mygit/Titanic-Survival/titansurv/pipeline/data_pipeline.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_dp_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train_score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/main/coding/Python-code/mygit/Titanic-Survival/titansurv/pipeline/data_pipeline.py\u001b[0m in \u001b[0;36m_check_dp_is_fitted\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_dp_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_fitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mDataPipelineNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please fit the data first using the fit method!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataPipelineNotFittedError\u001b[0m: Please fit the data first using the fit method!"
     ]
    }
   ],
   "source": [
    "dp.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX, dfy = dp.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessing',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('enc',\n",
       "                                                  OneHotEncoder(categories='auto',\n",
       "                                                                drop='first',\n",
       "                                                                dtype=<class 'numpy.float64'>,\n",
       "                                                                handle_unknown='error',\n",
       "                                                                sparse=True),\n",
       "                                                  ['Sex', 'Embarked']),\n",
       "                                                 ('imp_scaler',\n",
       "                                                  Pipeline(memory='passthrough',\n",
       "                                                           steps=[('i...\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=None, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = dp.get_pipeline()\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The following were the preprocessing steps used: \n",
       "1. **Embarked**: Dropped NA rows and applied OneHotEncoding\n",
       "2. **Age** : Applied Mean Imputation and Mean Normalization\n",
       "3. **Fare**: Mean Normalization\n",
       "4. **Sex**: OneHotEncoding\n",
       "5. **Name**: Categorised into ['Mr', 'Mrs', 'Miss', 'Master', 'Special']<br/> \n",
       "    5.1 Rename [Mlle, Ms] -> Miss      \n",
       "    5.2 Rename [Mme] -> Mrs     \n",
       "    5.3 Put the Rest -> Special     \n",
       "    Then performed OneHotEncoding\n",
       "6. **Ticket** categorized into [1: numeric, 0: else] <br/>\n",
       "    6.1 Remove special characters but not space <br/>\n",
       "    6.2 Replace numeric strings by 'numeric' <br/>\n",
       "    6.3 Split on space and keep the first item <br/>\n",
       " Then applied binarizer for [1: numeric, 0: else]\n",
       "7. **SibSp** binned into [0, 1, >1] and applied OneHotEncoding\n",
       "8. **Parch** binned into [0, 1, >1] and applied OneHotEncoding\n",
       "\n",
       "Tuned ML model: **RandomForestClassifier** using GridSearchCV"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dp.get_description(markdown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "DataPipelineNotFittedError",
     "evalue": "Please fit the data first using the fit method!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataPipelineNotFittedError\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-3d2d99b72765>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/main/coding/Python-code/mygit/Titanic-Survival/titansurv/pipeline/data_pipeline.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_dp_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train_score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/main/coding/Python-code/mygit/Titanic-Survival/titansurv/pipeline/data_pipeline.py\u001b[0m in \u001b[0;36m_check_dp_is_fitted\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_dp_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_fitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mDataPipelineNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please fit the data first using the fit method!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataPipelineNotFittedError\u001b[0m: Please fit the data first using the fit method!"
     ]
    }
   ],
   "source": [
    "dp.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from titansurv.pipeline import pipeline1 as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The following were the preprocessing steps used: \n",
       "1. **Embarked**: Dropped NA rows and applied OneHotEncoding\n",
       "2. **Age** : Applied Mean Imputation and Mean Normalization\n",
       "3. **Fare**: Mean Normalization\n",
       "4. **Sex**: OneHotEncoding\n",
       "5. **Name**: Categorised into ['Mr', 'Mrs', 'Miss', 'Master', 'Special']<br/> \n",
       "    5.1 Rename [Mlle, Ms] -> Miss      \n",
       "    5.2 Rename [Mme] -> Mrs     \n",
       "    5.3 Put the Rest -> Special     \n",
       "    Then performed OneHotEncoding\n",
       "6. **Ticket** categorized into [1: numeric, 0: else] <br/>\n",
       "    6.1 Remove special characters but not space <br/>\n",
       "    6.2 Replace numeric strings by 'numeric' <br/>\n",
       "    6.3 Split on space and keep the first item <br/>\n",
       " Then applied binarizer for [1: numeric, 0: else]\n",
       "7. **SibSp** binned into [0, 1, >1] and applied OneHotEncoding\n",
       "8. **Parch** binned into [0, 1, >1] and applied OneHotEncoding\n",
       "\n",
       "Tuned ML model: **RandomForestClassifier** using GridSearchCV"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dp.get_description(markdown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.set_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from titansurv.utils import print_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data',\n",
      " 'description',\n",
      " 'mlmodel__bootstrap',\n",
      " 'mlmodel__ccp_alpha',\n",
      " 'mlmodel__class_weight',\n",
      " 'mlmodel__criterion',\n",
      " 'mlmodel__max_depth',\n",
      " 'mlmodel__max_features',\n",
      " 'mlmodel__max_leaf_nodes',\n",
      " 'mlmodel__max_samples',\n",
      " 'mlmodel__min_impurity_decrease',\n",
      " 'mlmodel__min_impurity_split',\n",
      " 'mlmodel__min_samples_leaf',\n",
      " 'mlmodel__min_samples_split',\n",
      " 'mlmodel__min_weight_fraction_leaf',\n",
      " 'mlmodel__n_estimators',\n",
      " 'mlmodel__n_jobs',\n",
      " 'mlmodel__oob_score',\n",
      " 'mlmodel__random_state',\n",
      " 'mlmodel__verbose',\n",
      " 'mlmodel__warm_start',\n",
      " 'mlmodel',\n",
      " 'prepare_data__memory',\n",
      " 'prepare_data__steps',\n",
      " 'prepare_data__verbose',\n",
      " 'prepare_data__nan_drpr',\n",
      " 'prepare_data__nan_drpr__key',\n",
      " 'prepare_data',\n",
      " 'preprocess_data__n_jobs',\n",
      " 'preprocess_data__remainder',\n",
      " 'preprocess_data__sparse_threshold',\n",
      " 'preprocess_data__transformer_weights',\n",
      " 'preprocess_data__transformers',\n",
      " 'preprocess_data__verbose',\n",
      " 'preprocess_data__enc',\n",
      " 'preprocess_data__imp_scaler',\n",
      " 'preprocess_data__pre_Name',\n",
      " 'preprocess_data__pre_Cabin',\n",
      " 'preprocess_data__pre_Ticket',\n",
      " 'preprocess_data__Pre_SibSp',\n",
      " 'preprocess_data__Pre_Parch',\n",
      " 'preprocess_data__enc__categories',\n",
      " 'preprocess_data__enc__drop',\n",
      " 'preprocess_data__enc__dtype',\n",
      " 'preprocess_data__enc__handle_unknown',\n",
      " 'preprocess_data__enc__sparse',\n",
      " 'preprocess_data__imp_scaler__memory',\n",
      " 'preprocess_data__imp_scaler__steps',\n",
      " 'preprocess_data__imp_scaler__verbose',\n",
      " 'preprocess_data__imp_scaler__imp',\n",
      " 'preprocess_data__imp_scaler__scaler',\n",
      " 'preprocess_data__imp_scaler__imp__add_indicator',\n",
      " 'preprocess_data__imp_scaler__imp__copy',\n",
      " 'preprocess_data__imp_scaler__imp__fill_value',\n",
      " 'preprocess_data__imp_scaler__imp__missing_values',\n",
      " 'preprocess_data__imp_scaler__imp__strategy',\n",
      " 'preprocess_data__imp_scaler__imp__verbose',\n",
      " 'preprocess_data__imp_scaler__scaler__copy',\n",
      " 'preprocess_data__imp_scaler__scaler__with_mean',\n",
      " 'preprocess_data__imp_scaler__scaler__with_std',\n",
      " 'preprocess_data__pre_Name__memory',\n",
      " 'preprocess_data__pre_Name__steps',\n",
      " 'preprocess_data__pre_Name__verbose',\n",
      " 'preprocess_data__pre_Name__featurize',\n",
      " 'preprocess_data__pre_Name__enc',\n",
      " 'preprocess_data__pre_Name__featurize__accept_sparse',\n",
      " 'preprocess_data__pre_Name__featurize__check_inverse',\n",
      " 'preprocess_data__pre_Name__featurize__func',\n",
      " 'preprocess_data__pre_Name__featurize__inv_kw_args',\n",
      " 'preprocess_data__pre_Name__featurize__inverse_func',\n",
      " 'preprocess_data__pre_Name__featurize__kw_args',\n",
      " 'preprocess_data__pre_Name__featurize__validate',\n",
      " 'preprocess_data__pre_Name__enc__categories',\n",
      " 'preprocess_data__pre_Name__enc__drop',\n",
      " 'preprocess_data__pre_Name__enc__dtype',\n",
      " 'preprocess_data__pre_Name__enc__handle_unknown',\n",
      " 'preprocess_data__pre_Name__enc__sparse',\n",
      " 'preprocess_data__pre_Cabin__memory',\n",
      " 'preprocess_data__pre_Cabin__steps',\n",
      " 'preprocess_data__pre_Cabin__verbose',\n",
      " 'preprocess_data__pre_Cabin__featurize',\n",
      " 'preprocess_data__pre_Cabin__enc',\n",
      " 'preprocess_data__pre_Cabin__featurize__accept_sparse',\n",
      " 'preprocess_data__pre_Cabin__featurize__check_inverse',\n",
      " 'preprocess_data__pre_Cabin__featurize__func',\n",
      " 'preprocess_data__pre_Cabin__featurize__inv_kw_args',\n",
      " 'preprocess_data__pre_Cabin__featurize__inverse_func',\n",
      " 'preprocess_data__pre_Cabin__featurize__kw_args',\n",
      " 'preprocess_data__pre_Cabin__featurize__validate',\n",
      " 'preprocess_data__pre_Cabin__enc__categories',\n",
      " 'preprocess_data__pre_Cabin__enc__drop',\n",
      " 'preprocess_data__pre_Cabin__enc__dtype',\n",
      " 'preprocess_data__pre_Cabin__enc__handle_unknown',\n",
      " 'preprocess_data__pre_Cabin__enc__sparse',\n",
      " 'preprocess_data__pre_Ticket__memory',\n",
      " 'preprocess_data__pre_Ticket__steps',\n",
      " 'preprocess_data__pre_Ticket__verbose',\n",
      " 'preprocess_data__pre_Ticket__featurize',\n",
      " 'preprocess_data__pre_Ticket__binarizer',\n",
      " 'preprocess_data__pre_Ticket__featurize__accept_sparse',\n",
      " 'preprocess_data__pre_Ticket__featurize__check_inverse',\n",
      " 'preprocess_data__pre_Ticket__featurize__func',\n",
      " 'preprocess_data__pre_Ticket__featurize__inv_kw_args',\n",
      " 'preprocess_data__pre_Ticket__featurize__inverse_func',\n",
      " 'preprocess_data__pre_Ticket__featurize__kw_args',\n",
      " 'preprocess_data__pre_Ticket__featurize__validate',\n",
      " 'preprocess_data__pre_Ticket__binarizer__accept_sparse',\n",
      " 'preprocess_data__pre_Ticket__binarizer__check_inverse',\n",
      " 'preprocess_data__pre_Ticket__binarizer__func',\n",
      " 'preprocess_data__pre_Ticket__binarizer__inv_kw_args',\n",
      " 'preprocess_data__pre_Ticket__binarizer__inverse_func',\n",
      " 'preprocess_data__pre_Ticket__binarizer__kw_args',\n",
      " 'preprocess_data__pre_Ticket__binarizer__validate',\n",
      " 'preprocess_data__Pre_SibSp__memory',\n",
      " 'preprocess_data__Pre_SibSp__steps',\n",
      " 'preprocess_data__Pre_SibSp__verbose',\n",
      " 'preprocess_data__Pre_SibSp__binner',\n",
      " 'preprocess_data__Pre_SibSp__enc',\n",
      " 'preprocess_data__Pre_SibSp__binner__accept_sparse',\n",
      " 'preprocess_data__Pre_SibSp__binner__check_inverse',\n",
      " 'preprocess_data__Pre_SibSp__binner__func',\n",
      " 'preprocess_data__Pre_SibSp__binner__inv_kw_args',\n",
      " 'preprocess_data__Pre_SibSp__binner__inverse_func',\n",
      " 'preprocess_data__Pre_SibSp__binner__kw_args',\n",
      " 'preprocess_data__Pre_SibSp__binner__validate',\n",
      " 'preprocess_data__Pre_SibSp__enc__categories',\n",
      " 'preprocess_data__Pre_SibSp__enc__drop',\n",
      " 'preprocess_data__Pre_SibSp__enc__dtype',\n",
      " 'preprocess_data__Pre_SibSp__enc__handle_unknown',\n",
      " 'preprocess_data__Pre_SibSp__enc__sparse',\n",
      " 'preprocess_data__Pre_Parch__memory',\n",
      " 'preprocess_data__Pre_Parch__steps',\n",
      " 'preprocess_data__Pre_Parch__verbose',\n",
      " 'preprocess_data__Pre_Parch__binner',\n",
      " 'preprocess_data__Pre_Parch__enc',\n",
      " 'preprocess_data__Pre_Parch__binner__accept_sparse',\n",
      " 'preprocess_data__Pre_Parch__binner__check_inverse',\n",
      " 'preprocess_data__Pre_Parch__binner__func',\n",
      " 'preprocess_data__Pre_Parch__binner__inv_kw_args',\n",
      " 'preprocess_data__Pre_Parch__binner__inverse_func',\n",
      " 'preprocess_data__Pre_Parch__binner__kw_args',\n",
      " 'preprocess_data__Pre_Parch__binner__validate',\n",
      " 'preprocess_data__Pre_Parch__enc__categories',\n",
      " 'preprocess_data__Pre_Parch__enc__drop',\n",
      " 'preprocess_data__Pre_Parch__enc__dtype',\n",
      " 'preprocess_data__Pre_Parch__enc__handle_unknown',\n",
      " 'preprocess_data__Pre_Parch__enc__sparse',\n",
      " 'preprocess_data',\n",
      " 'ycol',\n",
      " 'preprocessing',\n",
      " 'train',\n",
      " 'preprocessing__n_jobs',\n",
      " 'preprocessing__remainder',\n",
      " 'preprocessing__sparse_threshold',\n",
      " 'preprocessing__transformer_weights',\n",
      " 'preprocessing__transformers',\n",
      " 'preprocessing__verbose',\n",
      " 'preprocessing__enc',\n",
      " 'preprocessing__imp_scaler',\n",
      " 'preprocessing__pre_Name',\n",
      " 'preprocessing__pre_Cabin',\n",
      " 'preprocessing__pre_Ticket',\n",
      " 'preprocessing__Pre_SibSp',\n",
      " 'preprocessing__Pre_Parch',\n",
      " 'preprocessing__enc__categories',\n",
      " 'preprocessing__enc__drop',\n",
      " 'preprocessing__enc__dtype',\n",
      " 'preprocessing__enc__handle_unknown',\n",
      " 'preprocessing__enc__sparse',\n",
      " 'preprocessing__imp_scaler__memory',\n",
      " 'preprocessing__imp_scaler__steps',\n",
      " 'preprocessing__imp_scaler__verbose',\n",
      " 'preprocessing__imp_scaler__imp',\n",
      " 'preprocessing__imp_scaler__scaler',\n",
      " 'preprocessing__imp_scaler__imp__add_indicator',\n",
      " 'preprocessing__imp_scaler__imp__copy',\n",
      " 'preprocessing__imp_scaler__imp__fill_value',\n",
      " 'preprocessing__imp_scaler__imp__missing_values',\n",
      " 'preprocessing__imp_scaler__imp__strategy',\n",
      " 'preprocessing__imp_scaler__imp__verbose',\n",
      " 'preprocessing__imp_scaler__scaler__copy',\n",
      " 'preprocessing__imp_scaler__scaler__with_mean',\n",
      " 'preprocessing__imp_scaler__scaler__with_std',\n",
      " 'preprocessing__pre_Name__memory',\n",
      " 'preprocessing__pre_Name__steps',\n",
      " 'preprocessing__pre_Name__verbose',\n",
      " 'preprocessing__pre_Name__featurize',\n",
      " 'preprocessing__pre_Name__enc',\n",
      " 'preprocessing__pre_Name__featurize__accept_sparse',\n",
      " 'preprocessing__pre_Name__featurize__check_inverse',\n",
      " 'preprocessing__pre_Name__featurize__func',\n",
      " 'preprocessing__pre_Name__featurize__inv_kw_args',\n",
      " 'preprocessing__pre_Name__featurize__inverse_func',\n",
      " 'preprocessing__pre_Name__featurize__kw_args',\n",
      " 'preprocessing__pre_Name__featurize__validate',\n",
      " 'preprocessing__pre_Name__enc__categories',\n",
      " 'preprocessing__pre_Name__enc__drop',\n",
      " 'preprocessing__pre_Name__enc__dtype',\n",
      " 'preprocessing__pre_Name__enc__handle_unknown',\n",
      " 'preprocessing__pre_Name__enc__sparse',\n",
      " 'preprocessing__pre_Cabin__memory',\n",
      " 'preprocessing__pre_Cabin__steps',\n",
      " 'preprocessing__pre_Cabin__verbose',\n",
      " 'preprocessing__pre_Cabin__featurize',\n",
      " 'preprocessing__pre_Cabin__enc',\n",
      " 'preprocessing__pre_Cabin__featurize__accept_sparse',\n",
      " 'preprocessing__pre_Cabin__featurize__check_inverse',\n",
      " 'preprocessing__pre_Cabin__featurize__func',\n",
      " 'preprocessing__pre_Cabin__featurize__inv_kw_args',\n",
      " 'preprocessing__pre_Cabin__featurize__inverse_func',\n",
      " 'preprocessing__pre_Cabin__featurize__kw_args',\n",
      " 'preprocessing__pre_Cabin__featurize__validate',\n",
      " 'preprocessing__pre_Cabin__enc__categories',\n",
      " 'preprocessing__pre_Cabin__enc__drop',\n",
      " 'preprocessing__pre_Cabin__enc__dtype',\n",
      " 'preprocessing__pre_Cabin__enc__handle_unknown',\n",
      " 'preprocessing__pre_Cabin__enc__sparse',\n",
      " 'preprocessing__pre_Ticket__memory',\n",
      " 'preprocessing__pre_Ticket__steps',\n",
      " 'preprocessing__pre_Ticket__verbose',\n",
      " 'preprocessing__pre_Ticket__featurize',\n",
      " 'preprocessing__pre_Ticket__binarizer',\n",
      " 'preprocessing__pre_Ticket__featurize__accept_sparse',\n",
      " 'preprocessing__pre_Ticket__featurize__check_inverse',\n",
      " 'preprocessing__pre_Ticket__featurize__func',\n",
      " 'preprocessing__pre_Ticket__featurize__inv_kw_args',\n",
      " 'preprocessing__pre_Ticket__featurize__inverse_func',\n",
      " 'preprocessing__pre_Ticket__featurize__kw_args',\n",
      " 'preprocessing__pre_Ticket__featurize__validate',\n",
      " 'preprocessing__pre_Ticket__binarizer__accept_sparse',\n",
      " 'preprocessing__pre_Ticket__binarizer__check_inverse',\n",
      " 'preprocessing__pre_Ticket__binarizer__func',\n",
      " 'preprocessing__pre_Ticket__binarizer__inv_kw_args',\n",
      " 'preprocessing__pre_Ticket__binarizer__inverse_func',\n",
      " 'preprocessing__pre_Ticket__binarizer__kw_args',\n",
      " 'preprocessing__pre_Ticket__binarizer__validate',\n",
      " 'preprocessing__Pre_SibSp__memory',\n",
      " 'preprocessing__Pre_SibSp__steps',\n",
      " 'preprocessing__Pre_SibSp__verbose',\n",
      " 'preprocessing__Pre_SibSp__binner',\n",
      " 'preprocessing__Pre_SibSp__enc',\n",
      " 'preprocessing__Pre_SibSp__binner__accept_sparse',\n",
      " 'preprocessing__Pre_SibSp__binner__check_inverse',\n",
      " 'preprocessing__Pre_SibSp__binner__func',\n",
      " 'preprocessing__Pre_SibSp__binner__inv_kw_args',\n",
      " 'preprocessing__Pre_SibSp__binner__inverse_func',\n",
      " 'preprocessing__Pre_SibSp__binner__kw_args',\n",
      " 'preprocessing__Pre_SibSp__binner__validate',\n",
      " 'preprocessing__Pre_SibSp__enc__categories',\n",
      " 'preprocessing__Pre_SibSp__enc__drop',\n",
      " 'preprocessing__Pre_SibSp__enc__dtype',\n",
      " 'preprocessing__Pre_SibSp__enc__handle_unknown',\n",
      " 'preprocessing__Pre_SibSp__enc__sparse',\n",
      " 'preprocessing__Pre_Parch__memory',\n",
      " 'preprocessing__Pre_Parch__steps',\n",
      " 'preprocessing__Pre_Parch__verbose',\n",
      " 'preprocessing__Pre_Parch__binner',\n",
      " 'preprocessing__Pre_Parch__enc',\n",
      " 'preprocessing__Pre_Parch__binner__accept_sparse',\n",
      " 'preprocessing__Pre_Parch__binner__check_inverse',\n",
      " 'preprocessing__Pre_Parch__binner__func',\n",
      " 'preprocessing__Pre_Parch__binner__inv_kw_args',\n",
      " 'preprocessing__Pre_Parch__binner__inverse_func',\n",
      " 'preprocessing__Pre_Parch__binner__kw_args',\n",
      " 'preprocessing__Pre_Parch__binner__validate',\n",
      " 'preprocessing__Pre_Parch__enc__categories',\n",
      " 'preprocessing__Pre_Parch__enc__drop',\n",
      " 'preprocessing__Pre_Parch__enc__dtype',\n",
      " 'preprocessing__Pre_Parch__enc__handle_unknown',\n",
      " 'preprocessing__Pre_Parch__enc__sparse',\n",
      " 'train__bootstrap',\n",
      " 'train__ccp_alpha',\n",
      " 'train__class_weight',\n",
      " 'train__criterion',\n",
      " 'train__max_depth',\n",
      " 'train__max_features',\n",
      " 'train__max_leaf_nodes',\n",
      " 'train__max_samples',\n",
      " 'train__min_impurity_decrease',\n",
      " 'train__min_impurity_split',\n",
      " 'train__min_samples_leaf',\n",
      " 'train__min_samples_split',\n",
      " 'train__min_weight_fraction_leaf',\n",
      " 'train__n_estimators',\n",
      " 'train__n_jobs',\n",
      " 'train__oob_score',\n",
      " 'train__random_state',\n",
      " 'train__verbose',\n",
      " 'train__warm_start']\n"
     ]
    }
   ],
   "source": [
    "print_params(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(dp, {'train__n_estimators': [10, 20]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             ('estimator', DataPipeline),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'train__n_estimators': [10, 20]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(dfX, dfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98989898989899"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:titansurv] *",
   "language": "python",
   "name": "conda-env-titansurv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
