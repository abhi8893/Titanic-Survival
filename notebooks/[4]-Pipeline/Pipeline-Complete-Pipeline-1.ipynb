{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Tune your preprocessing steps and algorithm selection like hyperparameters](https://medium.com/@moritzkoerber/tune-your-preprocessing-steps-and-algorithm-selection-like-hyperparameters-c817e6572335)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The various different preprocessing pipelines can be achieved by:\n",
    "\n",
    "1. Including a specific subset of the features\n",
    "2. Just for understanding, see how LabelEncoding should not be used as against OneHotEncoding\n",
    "3. Try OneHotEncoding v/s Ordinal encoding for ordinal variables\n",
    "4. Try continuous variables with or without binning/discretization\n",
    "5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T08:56:27.832266Z",
     "start_time": "2020-05-15T08:56:27.775151Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T08:56:28.185874Z",
     "start_time": "2020-05-15T08:56:28.150685Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.utils import load_data\n",
    "\n",
    "dfX, dfy  = load_data(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example creation of a preprocessing pipeline\n",
    "\n",
    "1. Drop Name, Ticket - requires Feature Engineering\n",
    "2. OneHotEncoder for Sex\n",
    "3. Drop Cabin - requires Feature Engineering/(?And Not Imputation)\n",
    "4. Impute Age with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T08:56:28.969717Z",
     "start_time": "2020-05-15T08:56:28.958052Z"
    }
   },
   "outputs": [],
   "source": [
    "trnsfrmr = ColumnTransformer([\n",
    "    ('imputer', SimpleImputer(), ['Age']),\n",
    "    ('ohe', OneHotEncoder(drop='first'), ['Sex', 'Embarked'])\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can either start with creating a dataframe by \n",
    "- dropping 'Name', 'Ticket', and 'Cabin'\n",
    "- dropping rows corresponding to NA values in Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T08:56:50.274857Z",
     "start_time": "2020-05-15T08:56:50.228882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0       3    male  22.0      1      0   7.2500        S\n",
       "1       1  female  38.0      1      0  71.2833        C\n",
       "2       3  female  26.0      0      0   7.9250        S\n",
       "3       1  female  35.0      1      0  53.1000        S\n",
       "4       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfX_pre = dfX.drop(['Name', 'Ticket', 'Cabin'], axis=1).loc[~dfX.Embarked.isna(), :]\n",
    "dfX_pre.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then use the Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T08:57:04.698457Z",
     "start_time": "2020-05-15T08:57:04.672821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.       ,  1.       ,  0.       , ...,  1.       ,  0.       ,\n",
       "         7.25     ],\n",
       "       [38.       ,  0.       ,  0.       , ...,  1.       ,  0.       ,\n",
       "        71.2833   ],\n",
       "       [26.       ,  0.       ,  0.       , ...,  0.       ,  0.       ,\n",
       "         7.925    ],\n",
       "       ...,\n",
       "       [29.6420927,  0.       ,  0.       , ...,  1.       ,  2.       ,\n",
       "        23.45     ],\n",
       "       [26.       ,  1.       ,  0.       , ...,  0.       ,  0.       ,\n",
       "        30.       ],\n",
       "       [32.       ,  1.       ,  1.       , ...,  0.       ,  0.       ,\n",
       "         7.75     ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1 = trnsfrmr.fit_transform(dfX_pre)\n",
    "res1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T11:32:51.935237Z",
     "start_time": "2020-04-26T11:32:51.931914Z"
    }
   },
   "source": [
    "Or you can just make a preprocess pipeline out of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T08:57:07.816331Z",
     "start_time": "2020-05-15T08:57:07.806656Z"
    }
   },
   "outputs": [],
   "source": [
    "class ColumnDropper(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X.drop(self.key, axis=1)\n",
    "    \n",
    "    \n",
    "class NaNDropper(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.nan_indices = X.loc[:, self.key].isna().any(axis=1) | y.isna()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        if y is None:\n",
    "            return X.loc[~self.nan_indices]\n",
    "        else:\n",
    "            return X.loc[~self.nan_indices], y.loc[~self.nan_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T08:57:08.560258Z",
     "start_time": "2020-05-15T08:57:08.557546Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocess = Pipeline([\n",
    "    ('clmn_dropper', ColumnDropper(['Name', 'Ticket', 'Cabin'])),\n",
    "    ('nan_dropper', NaNDropper(['Embarked'])),\n",
    "    ('trnsfrmr', trnsfrmr)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T08:57:14.529965Z",
     "start_time": "2020-05-15T08:57:14.494339Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.       ,  1.       ,  0.       , ...,  1.       ,  0.       ,\n",
       "         7.25     ],\n",
       "       [38.       ,  0.       ,  0.       , ...,  1.       ,  0.       ,\n",
       "        71.2833   ],\n",
       "       [26.       ,  0.       ,  0.       , ...,  0.       ,  0.       ,\n",
       "         7.925    ],\n",
       "       ...,\n",
       "       [29.6420927,  0.       ,  0.       , ...,  1.       ,  2.       ,\n",
       "        23.45     ],\n",
       "       [26.       ,  1.       ,  0.       , ...,  0.       ,  0.       ,\n",
       "        30.       ],\n",
       "       [32.       ,  1.       ,  1.       , ...,  0.       ,  0.       ,\n",
       "         7.75     ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2 = preprocess.fit_transform(dfX, dfy)\n",
    "res2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the results we got were the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T08:57:42.427441Z",
     "start_time": "2020-05-15T08:57:42.416477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.equal(res1, res2).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T08:57:43.058344Z",
     "start_time": "2020-05-15T08:57:43.045086Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "('preprocess', preprocess),\n",
    "('clf', KNeighborsClassifier(5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T08:58:20.484536Z",
     "start_time": "2020-05-15T08:58:20.432251Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [889, 891]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3ac48071c426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/titansurv/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    352\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/titansurv/lib/python3.8/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1124\u001b[0m         \"\"\"\n\u001b[1;32m   1125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1126\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/titansurv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/titansurv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    212\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [889, 891]"
     ]
    }
   ],
   "source": [
    "pipe.fit(dfX, dfy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But Bad Luck :(, since we changed the sample size by dropping the NaN rows, the input and output variables had inconsistent sizes. See the following links on the issue:\n",
    "\n",
    "- https://github.com/scikit-learn/scikit-learn/issues/3855\n",
    "- https://stackoverflow.com/questions/25539311/custom-transformer-for-sklearn-pipeline-that-alters-both-x-and-y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping in mind the above issue, this is how our general workflow will look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T08:58:25.645702Z",
     "start_time": "2020-05-15T08:58:25.637701Z"
    }
   },
   "outputs": [],
   "source": [
    "class AutoFitTrans:\n",
    "    '''\n",
    "    Use this to implement fit\n",
    "    '''\n",
    "    \n",
    "    def fit(self):\n",
    "        pass\n",
    "    \n",
    "    def transform(self):\n",
    "        pass\n",
    "    \n",
    "    def fit_transform(self, *args, **kwargs):\n",
    "        return self.fit(*args, **kwargs).transform(*args, **kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T08:58:26.103723Z",
     "start_time": "2020-05-15T08:58:26.088531Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Can I implement this to support both dataframes and arrays?\n",
    "# TODO: Implement key='auto' to drop all NaNs\n",
    "class NaNDropper(BaseEstimator, ClassifierMixin, AutoFitTrans):\n",
    "    \n",
    "    '''Drops rows with NaN values\n",
    "    \n",
    "    key: list-like\n",
    "        A list of keys(column names) to consider while dropping NaN values\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        '''Fits the model and extracts indices with missing values\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        X: pd.DataFrame\n",
    "        y: pd.Series (Default: None)\n",
    "        '''\n",
    "        \n",
    "        self.nan_indices = X.loc[:, self.key].isna().any(axis=1) | y.isna()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        if y is None:\n",
    "            return X.loc[~self.nan_indices]\n",
    "        else:\n",
    "            return X.loc[~self.nan_indices], y.loc[~self.nan_indices]\n",
    "        \n",
    "#     def fit_transform(self, X, y=None):\n",
    "#         return self.fit(X, y).transform(X, y)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:02:22.500859Z",
     "start_time": "2020-04-27T07:02:22.480848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(889, 10) (889,)\n"
     ]
    }
   ],
   "source": [
    "# Do any sample size altering steps before the pipeline\n",
    "\n",
    "preprocess_pre = Pipeline([\n",
    "    ('nan_dropper', NaNDropper(['Embarked']))])\n",
    "\n",
    "dfX_pre, dfy_pre = preprocess_pre.fit_transform(df_X, df_y)\n",
    "\n",
    "print(df_pre_X.shape, df_pre_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:02:23.528123Z",
     "start_time": "2020-04-27T07:02:23.482922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocess',\n",
       "                 Pipeline(memory=None,\n",
       "                          steps=[('clmn_dropper',\n",
       "                                  ColumnDropper(key=['Name', 'Ticket',\n",
       "                                                     'Cabin'])),\n",
       "                                 ('trnsfrmr',\n",
       "                                  ColumnTransformer(n_jobs=None,\n",
       "                                                    remainder='passthrough',\n",
       "                                                    sparse_threshold=0.3,\n",
       "                                                    transformer_weights=None,\n",
       "                                                    transformers=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 st...\n",
       "                                                                                 verbose=0),\n",
       "                                                                   ['Age']),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(categories='auto',\n",
       "                                                                                 drop='first',\n",
       "                                                                                 dtype=<class 'numpy.float64'>,\n",
       "                                                                                 handle_unknown='error',\n",
       "                                                                                 sparse=True),\n",
       "                                                                   ['Sex',\n",
       "                                                                    'Embarked'])],\n",
       "                                                    verbose=False))],\n",
       "                          verbose=False)),\n",
       "                ('clf',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=None, n_neighbors=5, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now define the preprocessing step\n",
    "\n",
    "trnsfrmr = ColumnTransformer([\n",
    "    ('imputer', SimpleImputer(), ['Age']),\n",
    "    ('ohe', OneHotEncoder(drop='first'), ['Sex', 'Embarked'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "preprocess = Pipeline([\n",
    "    ('clmn_dropper', ColumnDropper(['Name', 'Ticket', 'Cabin'])),\n",
    "    ('trnsfrmr', trnsfrmr)\n",
    "])\n",
    "\n",
    "\n",
    "# Now define the whole pipeline\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocess', preprocess),\n",
    "    ('clf', KNeighborsClassifier(5))\n",
    "])\n",
    "\n",
    "# Now fit\n",
    "pipe.fit(df_pre_X, df_pre_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:02:54.302436Z",
     "start_time": "2020-04-27T07:02:54.053167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6974974463738508"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe, df_pre_X, df_pre_y, cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila! Everything works! :D <br/>\n",
    "These are the further things we can explore:\n",
    "1. Hyperparameter tuning for the preprocessing step which changes sample size\n",
    "2. Hyperparameter tuning for the sklearn pipeline compatible preprocessing step\n",
    "3. Hyperparameter tuning for the ML model\n",
    "4. Try various different pipelines\n",
    "\n",
    "\n",
    "\n",
    "I think implementing the following structure may help in efficiently using pipelines: <br/>\n",
    "Implement a class for each WHOLE pipeline which implements the following methods:\n",
    "1. preprocess_pre - preprocessing step which changes sample size\n",
    "2. preprocess - sklearn pipeline compatible preprocessing step\n",
    "3. pipe - The pipeline containing step 2. and ML model fitting\n",
    "4. description - The description of the pipeline in natural language\n",
    "\n",
    "Ofcourse each of these steps will be implemented and placed in a module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-26T13:58:51.618732Z",
     "start_time": "2020-04-26T13:58:51.606201Z"
    }
   },
   "source": [
    "Note: Instead of making a different pipelines for each combination we need to properly identify how we can just different combinations by specifying different hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a pipeline with a specific hyperparameter combination. <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:03:52.008178Z",
     "start_time": "2020-04-27T07:03:51.995733Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {'nan_dropper__key': ['Age', 'Embarked']}\n",
    "preprocess_pre.set_params(**params)\n",
    "df_pre_X, df_pre_y = preprocess_pre.fit_transform(df_X, df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:03:52.428620Z",
     "start_time": "2020-04-27T07:03:52.402732Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age         False\n",
       "Embarked    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pre_X.loc[:, ['Age', 'Embarked']].isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it's verified we dropped the NaNs in our Age & Embarked column. We can other tests as well to see if it worked correctly or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same for the preprocessing step.<br/>\n",
    "First let's take a look at the names of these params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:03:53.182053Z",
     "start_time": "2020-04-27T07:03:53.174188Z"
    }
   },
   "outputs": [],
   "source": [
    "from pprint import PrettyPrinter\n",
    "pp = PrettyPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:03:53.471362Z",
     "start_time": "2020-04-27T07:03:53.455406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['memory',\n",
      " 'steps',\n",
      " 'verbose',\n",
      " 'clmn_dropper',\n",
      " 'trnsfrmr',\n",
      " 'clmn_dropper__key',\n",
      " 'trnsfrmr__n_jobs',\n",
      " 'trnsfrmr__remainder',\n",
      " 'trnsfrmr__sparse_threshold',\n",
      " 'trnsfrmr__transformer_weights',\n",
      " 'trnsfrmr__transformers',\n",
      " 'trnsfrmr__verbose',\n",
      " 'trnsfrmr__imputer',\n",
      " 'trnsfrmr__ohe',\n",
      " 'trnsfrmr__imputer__add_indicator',\n",
      " 'trnsfrmr__imputer__copy',\n",
      " 'trnsfrmr__imputer__fill_value',\n",
      " 'trnsfrmr__imputer__missing_values',\n",
      " 'trnsfrmr__imputer__strategy',\n",
      " 'trnsfrmr__imputer__verbose',\n",
      " 'trnsfrmr__ohe__categories',\n",
      " 'trnsfrmr__ohe__drop',\n",
      " 'trnsfrmr__ohe__dtype',\n",
      " 'trnsfrmr__ohe__handle_unknown',\n",
      " 'trnsfrmr__ohe__sparse']\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(list(preprocess.get_params().keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above will tell us the hyperparameters we can access. Sadly this doesn't include the columns. So we can create a Modded ColumnTransformer that will rectify and include columns as an argument in the \\_\\_init\\_\\_ signature, and therefore in the hyperparameters. \n",
    "\n",
    "But this has a problem, I can copy the init signature by using \\*args, \\*\\*kwargs but sklearn would throw a RunTimeError if all the keyword arguments aren't included explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:03:53.888627Z",
     "start_time": "2020-04-27T07:03:53.872942Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_ModTrnsfrmr(cls):\n",
    "    class ModTrnsfrmr(cls, AutoFitTrans): \n",
    "\n",
    "        def __init__(self, cols, *args, **kwargs):\n",
    "            self.__orig = super().__init__(*args, **kwargs)\n",
    "            self.cols = cols\n",
    "            \n",
    "        def fit(self, X, y=None):\n",
    "            return self.__orig.fit(X.loc[:, self.cols], y)\n",
    "            \n",
    "        def transform(self, ):\n",
    "            return self.__orig.transform(X.loc[:, self.cols])\n",
    "            \n",
    "                    \n",
    "    return ModTrnsfrmr\n",
    "        \n",
    "\n",
    "class ClmnTrnsfrmr(ColumnTransformer):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.__make_attrs()\n",
    "        \n",
    "    \n",
    "    def __make_attrs(self):\n",
    "        for i, (name, trnsfrmr, cols) in enumerate(self.transformers):\n",
    "            ModTrnsfrmr = make_ModTrnsfrmr(trnsfrmr.__class__)\n",
    "            modtrnsfrmr = ModTrnsfrmr(cols, **trnsfrmr.get_params())\n",
    "            self.transformers[i] = (name, modtrnsfrmr, cols)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative way is to just create another transformer instance from the ColumnTransformer and create a new preprocess pipeline based on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function to modify the columns in our old column transformer instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:03:54.708011Z",
     "start_time": "2020-04-27T07:03:54.691686Z"
    }
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def modify_transformer_cols(col_trnsfrmr: ColumnTransformer, append=False, **trnsfrmr_cols):\n",
    "    new_col_trnsfrmr = deepcopy(col_trnsfrmr)\n",
    "    trnsfrmrs = new_col_trnsfrmr.transformers\n",
    "    for i, [trnsfrmr_name, old_trnsfrmr, old_cols] in enumerate(trnsfrmrs):\n",
    "        new_cols = trnsfrmr_cols.get(trnsfrmr_name, None)\n",
    "        \n",
    "        if new_cols is not None:\n",
    "            if append:\n",
    "                new_cols  = list(set().union(new_cols, old_cols))\n",
    "        else:\n",
    "            new_cols = old_cols\n",
    "                            \n",
    "        trnsfrmrs[i] = (trnsfrmr_name, old_trnsfrmr, new_cols)\n",
    "        \n",
    "    return new_col_trnsfrmr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was our old column transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our modified column trnsfrmr with the following modifications:\n",
    "1. OneHotEncoding for Pclass in addition to Sex, Embarked (by setting append=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:03:55.996484Z",
     "start_time": "2020-04-27T07:03:55.975169Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(n_jobs=None, remainder='passthrough', sparse_threshold=0.3,\n",
       "                  transformer_weights=None,\n",
       "                  transformers=[('imputer',\n",
       "                                 SimpleImputer(add_indicator=False, copy=True,\n",
       "                                               fill_value=None,\n",
       "                                               missing_values=nan,\n",
       "                                               strategy='mean', verbose=0),\n",
       "                                 ['Age']),\n",
       "                                ('ohe',\n",
       "                                 OneHotEncoder(categories='auto', drop='first',\n",
       "                                               dtype=<class 'numpy.float64'>,\n",
       "                                               handle_unknown='error',\n",
       "                                               sparse=True),\n",
       "                                 ['Pclass', 'Embarked', 'Sex'])],\n",
       "                  verbose=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trnsfrmr_mod = modify_transformer_cols(trnsfrmr, append=True, ohe=['Pclass'])\n",
    "trnsfrmr_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was our old preprocess pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:03:57.127971Z",
     "start_time": "2020-04-27T07:03:57.099621Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('clmn_dropper',\n",
       "                 ColumnDropper(key=['Name', 'Ticket', 'Cabin'])),\n",
       "                ('trnsfrmr',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('imputer',\n",
       "                                                  SimpleImputer(add_indicator=False,\n",
       "                                                                copy=True,\n",
       "                                                                fill_value=None,\n",
       "                                                                missing_values=nan,\n",
       "                                                                strategy='mean',\n",
       "                                                                verbose=0),\n",
       "                                                  ['Age']),\n",
       "                                                 ('ohe',\n",
       "                                                  OneHotEncoder(categories='auto',\n",
       "                                                                drop='first',\n",
       "                                                                dtype=<class 'numpy.float64'>,\n",
       "                                                                handle_unknown='error',\n",
       "                                                                sparse=True),\n",
       "                                                  ['Sex', 'Embarked'])],\n",
       "                                   verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can include this change in our preprocessing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:03:58.196561Z",
     "start_time": "2020-04-27T07:03:58.167142Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('clmn_dropper',\n",
       "                 ColumnDropper(key=['Name', 'Ticket', 'Cabin'])),\n",
       "                ('trnsfrmr',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('imputer',\n",
       "                                                  SimpleImputer(add_indicator=False,\n",
       "                                                                copy=True,\n",
       "                                                                fill_value=None,\n",
       "                                                                missing_values=nan,\n",
       "                                                                strategy='mean',\n",
       "                                                                verbose=0),\n",
       "                                                  ['Age']),\n",
       "                                                 ('ohe',\n",
       "                                                  OneHotEncoder(categories='auto',\n",
       "                                                                drop='first',\n",
       "                                                                dtype=<class 'numpy.float64'>,\n",
       "                                                                handle_unknown='error',\n",
       "                                                                sparse=True),\n",
       "                                                  ['Pclass', 'Embarked',\n",
       "                                                   'Sex'])],\n",
       "                                   verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess.set_params(trnsfrmr=trnsfrmr_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:03:59.381127Z",
     "start_time": "2020-04-27T07:03:59.345128Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.    ,  0.    ,  1.    , ...,  1.    ,  0.    ,  7.25  ],\n",
       "       [38.    ,  0.    ,  0.    , ...,  1.    ,  0.    , 71.2833],\n",
       "       [26.    ,  0.    ,  1.    , ...,  0.    ,  0.    ,  7.925 ],\n",
       "       ...,\n",
       "       [19.    ,  0.    ,  0.    , ...,  0.    ,  0.    , 30.    ],\n",
       "       [26.    ,  0.    ,  0.    , ...,  0.    ,  0.    , 30.    ],\n",
       "       [32.    ,  0.    ,  1.    , ...,  0.    ,  0.    ,  7.75  ]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess.fit_transform(df_pre_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works! :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But ideally we would want to do it for the whole pipeline together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:04:00.820431Z",
     "start_time": "2020-04-27T07:04:00.811384Z"
    }
   },
   "outputs": [],
   "source": [
    "# preprocess pipeline\n",
    "\n",
    "preprocess = Pipeline([\n",
    "    ('clmn_dropper', ColumnDropper(['Name', 'Ticket', 'Cabin'])),\n",
    "    ('trnsfrmr', trnsfrmr)\n",
    "])\n",
    "\n",
    "# whole pipeline (sklearn compatible)\n",
    "pipe = Pipeline([\n",
    "    ('preprocess', preprocess),\n",
    "    ('clf', KNeighborsClassifier(5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:04:01.466147Z",
     "start_time": "2020-04-27T07:04:01.423535Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocess',\n",
       "                 Pipeline(memory=None,\n",
       "                          steps=[('clmn_dropper',\n",
       "                                  ColumnDropper(key=['Name', 'Ticket',\n",
       "                                                     'Cabin'])),\n",
       "                                 ('trnsfrmr',\n",
       "                                  ColumnTransformer(n_jobs=None,\n",
       "                                                    remainder='passthrough',\n",
       "                                                    sparse_threshold=0.3,\n",
       "                                                    transformer_weights=None,\n",
       "                                                    transformers=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 st...\n",
       "                                                                                 verbose=0),\n",
       "                                                                   ['Age']),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(categories='auto',\n",
       "                                                                                 drop='first',\n",
       "                                                                                 dtype=<class 'numpy.float64'>,\n",
       "                                                                                 handle_unknown='error',\n",
       "                                                                                 sparse=True),\n",
       "                                                                   ['Sex',\n",
       "                                                                    'Embarked'])],\n",
       "                                                    verbose=False))],\n",
       "                          verbose=False)),\n",
       "                ('clf',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=None, n_neighbors=5, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:04:02.067569Z",
     "start_time": "2020-04-27T07:04:02.009841Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocess',\n",
       "                 Pipeline(memory=None,\n",
       "                          steps=[('clmn_dropper',\n",
       "                                  ColumnDropper(key=['Name', 'Ticket',\n",
       "                                                     'Cabin'])),\n",
       "                                 ('trnsfrmr',\n",
       "                                  ColumnTransformer(n_jobs=None,\n",
       "                                                    remainder='passthrough',\n",
       "                                                    sparse_threshold=0.3,\n",
       "                                                    transformer_weights=None,\n",
       "                                                    transformers=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 st...\n",
       "                                                                   ['Age']),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(categories='auto',\n",
       "                                                                                 drop='first',\n",
       "                                                                                 dtype=<class 'numpy.float64'>,\n",
       "                                                                                 handle_unknown='error',\n",
       "                                                                                 sparse=True),\n",
       "                                                                   ['Pclass',\n",
       "                                                                    'Embarked',\n",
       "                                                                    'Sex'])],\n",
       "                                                    verbose=False))],\n",
       "                          verbose=False)),\n",
       "                ('clf',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=None, n_neighbors=5, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.set_params(preprocess__trnsfrmr=trnsfrmr_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:04:02.722150Z",
     "start_time": "2020-04-27T07:04:02.615058Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocess',\n",
       "                 Pipeline(memory=None,\n",
       "                          steps=[('clmn_dropper',\n",
       "                                  ColumnDropper(key=['Name', 'Ticket',\n",
       "                                                     'Cabin'])),\n",
       "                                 ('trnsfrmr',\n",
       "                                  ColumnTransformer(n_jobs=None,\n",
       "                                                    remainder='passthrough',\n",
       "                                                    sparse_threshold=0.3,\n",
       "                                                    transformer_weights=None,\n",
       "                                                    transformers=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 st...\n",
       "                                                                   ['Age']),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(categories='auto',\n",
       "                                                                                 drop='first',\n",
       "                                                                                 dtype=<class 'numpy.float64'>,\n",
       "                                                                                 handle_unknown='error',\n",
       "                                                                                 sparse=True),\n",
       "                                                                   ['Pclass',\n",
       "                                                                    'Embarked',\n",
       "                                                                    'Sex'])],\n",
       "                                                    verbose=False))],\n",
       "                          verbose=False)),\n",
       "                ('clf',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=None, n_neighbors=5, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(df_pre_X, df_pre_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:04:03.624204Z",
     "start_time": "2020-04-27T07:04:03.356602Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6897691705790298"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe, df_pre_X, df_pre_y, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:titansurv] *",
   "language": "python",
   "name": "conda-env-titansurv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
