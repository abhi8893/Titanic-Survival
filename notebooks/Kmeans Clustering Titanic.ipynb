{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using Clustering : KMeans "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will design a pipeline to first do clustering with Kmeans and then apply a classification algorithm on the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw/train.csv').drop('PassengerId', axis=1)\n",
    "dfX = df.drop('Survived', axis=1)\n",
    "dfy = df.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from titansurv.preprocessing.transformers import NaNDropper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre1 = Pipeline([\n",
    "    ('nan_drpr', NaNDropper(['Embarked']))\n",
    "])\n",
    "\n",
    "dfX, dfy = pre1.fit_transform(dfX, dfy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeansPredictor(KMeans):\n",
    "    \n",
    "    def __init__(self, n_clusters=8, init='k-means++', n_init=10,\n",
    "                 max_iter=300, tol=1e-4, precompute_distances='auto',\n",
    "                 verbose=0, random_state=None, copy_x=True,\n",
    "                 n_jobs=None, algorithm='auto'):\n",
    "        \n",
    "        super().__init__(\n",
    "            n_clusters, \n",
    "            init, \n",
    "            n_init, \n",
    "            max_iter,\n",
    "            tol,\n",
    "            precompute_distances,\n",
    "            verbose,\n",
    "            random_state,\n",
    "            copy_x,\n",
    "            n_jobs, \n",
    "            algorithm)\n",
    "        \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return self.predict(X).reshape(-1, 1)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit_predict(X).reshape(-1, 1)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre2 = Pipeline([\n",
    "    ('imp', SimpleImputer()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('cluster', KMeansPredictor()),\n",
    "    ('enc', OneHotEncoder(drop='first'))\n",
    "], 'passthrough')\n",
    "\n",
    "\n",
    "\n",
    "precomb2 = ColumnTransformer([\n",
    "    ('clmn_drpr', 'drop', ['Name', 'Ticket', 'Cabin']),\n",
    "    ('enc', OneHotEncoder(drop='first'), ['Sex', 'Embarked']),\n",
    "    ('imp_scaler', pre2, ['Age', 'Fare'])\n",
    "], 'passthrough')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster and Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocess', precomb2),\n",
    "    ('clf', LogisticRegression(solver='liblinear'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('preprocess',\n",
       "  ColumnTransformer(n_jobs=None, remainder='passthrough', sparse_threshold=0.3,\n",
       "                    transformer_weights=None,\n",
       "                    transformers=[('clmn_drpr', 'drop',\n",
       "                                   ['Name', 'Ticket', 'Cabin']),\n",
       "                                  ('enc',\n",
       "                                   OneHotEncoder(categories='auto', drop='first',\n",
       "                                                 dtype=<class 'numpy.float64'>,\n",
       "                                                 handle_unknown='error',\n",
       "                                                 sparse=True),\n",
       "                                   ['Sex', 'Embarked']),\n",
       "                                  ('imp_scaler',\n",
       "                                   Pipeline(memory='passthrough',\n",
       "                                            steps=[(...\n",
       "                                                   ('cluster',\n",
       "                                                    KMeansPredictor(algorithm='auto',\n",
       "                                                                    copy_x=True,\n",
       "                                                                    init='k-means++',\n",
       "                                                                    max_iter=300,\n",
       "                                                                    n_clusters=8,\n",
       "                                                                    n_init=10,\n",
       "                                                                    n_jobs=None,\n",
       "                                                                    precompute_distances='auto',\n",
       "                                                                    random_state=None,\n",
       "                                                                    tol=0.0001,\n",
       "                                                                    verbose=0)),\n",
       "                                                   ('enc',\n",
       "                                                    OneHotEncoder(categories='auto',\n",
       "                                                                  drop='first',\n",
       "                                                                  dtype=<class 'numpy.float64'>,\n",
       "                                                                  handle_unknown='error',\n",
       "                                                                  sparse=True))],\n",
       "                                            verbose=False),\n",
       "                                   ['Age', 'Fare'])],\n",
       "                    verbose=False)),\n",
       " ('clf',\n",
       "  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                     intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                     multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                     random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                     warm_start=False))]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocess',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('clmn_drpr', 'drop',\n",
       "                                                  ['Name', 'Ticket', 'Cabin']),\n",
       "                                                 ('enc',\n",
       "                                                  OneHotEncoder(categories='auto',\n",
       "                                                                drop='first',\n",
       "                                                                dtype=<class 'numpy.float64'>,\n",
       "                                                                handle_unknown='error',\n",
       "                                                                sparse=True),\n",
       "                                                  ['Sex', 'Embarked']),\n",
       "                                                 ('imp_scal...\n",
       "                                                                                 dtype=<class 'numpy.float64'>,\n",
       "                                                                                 handle_unknown='error',\n",
       "                                                                                 sparse=True))],\n",
       "                                                           verbose=False),\n",
       "                                                  ['Age', 'Fare'])],\n",
       "                                   verbose=False)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(dfX, dfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8155230596175478"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(dfX, dfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8054148416174696"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe, dfX, dfy).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from titansurv.utils import print_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune the Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['memory',\n",
      " 'steps',\n",
      " 'verbose',\n",
      " 'preprocess',\n",
      " 'clf',\n",
      " 'preprocess__n_jobs',\n",
      " 'preprocess__remainder',\n",
      " 'preprocess__sparse_threshold',\n",
      " 'preprocess__transformer_weights',\n",
      " 'preprocess__transformers',\n",
      " 'preprocess__verbose',\n",
      " 'preprocess__clmn_drpr',\n",
      " 'preprocess__enc',\n",
      " 'preprocess__imp_scaler',\n",
      " 'preprocess__enc__categories',\n",
      " 'preprocess__enc__drop',\n",
      " 'preprocess__enc__dtype',\n",
      " 'preprocess__enc__handle_unknown',\n",
      " 'preprocess__enc__sparse',\n",
      " 'preprocess__imp_scaler__memory',\n",
      " 'preprocess__imp_scaler__steps',\n",
      " 'preprocess__imp_scaler__verbose',\n",
      " 'preprocess__imp_scaler__imp',\n",
      " 'preprocess__imp_scaler__scaler',\n",
      " 'preprocess__imp_scaler__cluster',\n",
      " 'preprocess__imp_scaler__enc',\n",
      " 'preprocess__imp_scaler__imp__add_indicator',\n",
      " 'preprocess__imp_scaler__imp__copy',\n",
      " 'preprocess__imp_scaler__imp__fill_value',\n",
      " 'preprocess__imp_scaler__imp__missing_values',\n",
      " 'preprocess__imp_scaler__imp__strategy',\n",
      " 'preprocess__imp_scaler__imp__verbose',\n",
      " 'preprocess__imp_scaler__scaler__copy',\n",
      " 'preprocess__imp_scaler__scaler__with_mean',\n",
      " 'preprocess__imp_scaler__scaler__with_std',\n",
      " 'preprocess__imp_scaler__cluster__algorithm',\n",
      " 'preprocess__imp_scaler__cluster__copy_x',\n",
      " 'preprocess__imp_scaler__cluster__init',\n",
      " 'preprocess__imp_scaler__cluster__max_iter',\n",
      " 'preprocess__imp_scaler__cluster__n_clusters',\n",
      " 'preprocess__imp_scaler__cluster__n_init',\n",
      " 'preprocess__imp_scaler__cluster__n_jobs',\n",
      " 'preprocess__imp_scaler__cluster__precompute_distances',\n",
      " 'preprocess__imp_scaler__cluster__random_state',\n",
      " 'preprocess__imp_scaler__cluster__tol',\n",
      " 'preprocess__imp_scaler__cluster__verbose',\n",
      " 'preprocess__imp_scaler__enc__categories',\n",
      " 'preprocess__imp_scaler__enc__drop',\n",
      " 'preprocess__imp_scaler__enc__dtype',\n",
      " 'preprocess__imp_scaler__enc__handle_unknown',\n",
      " 'preprocess__imp_scaler__enc__sparse',\n",
      " 'clf__C',\n",
      " 'clf__class_weight',\n",
      " 'clf__dual',\n",
      " 'clf__fit_intercept',\n",
      " 'clf__intercept_scaling',\n",
      " 'clf__l1_ratio',\n",
      " 'clf__max_iter',\n",
      " 'clf__multi_class',\n",
      " 'clf__n_jobs',\n",
      " 'clf__penalty',\n",
      " 'clf__random_state',\n",
      " 'clf__solver',\n",
      " 'clf__tol',\n",
      " 'clf__verbose',\n",
      " 'clf__warm_start']\n"
     ]
    }
   ],
   "source": [
    "print_params(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 504 ms, sys: 0 ns, total: 504 ms\n",
      "Wall time: 502 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preprocess',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='passthrough',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('clmn_drpr',\n",
       "                                                                         'drop',\n",
       "                                                                         ['Name',\n",
       "                                                                          'Ticket',\n",
       "                                                                          'Cabin']),\n",
       "                                                                        ('enc',\n",
       "                                                                         OneHotEncoder(categories='auto',\n",
       "                                                                                       drop='first',\n",
       "                                                                                       dtype=<class 'numpy.float64'>,\n",
       "                                                                                       handle_unknown='err...\n",
       "                                                           intercept_scaling=1,\n",
       "                                                           l1_ratio=None,\n",
       "                                                           max_iter=100,\n",
       "                                                           multi_class='auto',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='liblinear',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'preprocess__imp_scaler__cluster__n_clusters': range(2, 12, 2)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'preprocess__imp_scaler__cluster__n_clusters': range(2, 12, 2)}\n",
    "grid = GridSearchCV(pipe, param_grid)\n",
    "grid.fit(dfX, dfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8054148416174696\n",
      "{'preprocess__imp_scaler__cluster__n_clusters': 8}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment KMeans Features using FeatureUnioun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment the Feature set using cluster labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "\n",
    "kmeans_augment = FeatureUnion([\n",
    "    (\"cluster\", KMeansPredictor()),\n",
    "    (\"original\", ColumnSelector())\n",
    "])\n",
    "\n",
    "\n",
    "pre2 = Pipeline([\n",
    "    ('imp', SimpleImputer()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('augment', kmeans_augment)\n",
    "], 'passthrough')\n",
    "\n",
    "\n",
    "\n",
    "precomb2 = ColumnTransformer([\n",
    "    ('clmn_drpr', 'drop', ['Name', 'Ticket', 'Cabin']),\n",
    "    ('enc', OneHotEncoder(drop='first'), ['Sex', 'Embarked']),\n",
    "    ('imp_scale_augment', pre2, ['Age', 'Fare'])\n",
    "], 'passthrough')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 9)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precomb2.fit_transform(dfX, dfy).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocess', precomb2),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocess',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('clmn_drpr', 'drop',\n",
       "                                                  ['Name', 'Ticket', 'Cabin']),\n",
       "                                                 ('enc',\n",
       "                                                  OneHotEncoder(categories='auto',\n",
       "                                                                drop='first',\n",
       "                                                                dtype=<class 'numpy.float64'>,\n",
       "                                                                handle_unknown='error',\n",
       "                                                                sparse=True),\n",
       "                                                  ['Sex', 'Embarked']),\n",
       "                                                 ('imp_scal...\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=None, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(dfX, dfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9820022497187851"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(dfX, dfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8132863581540024"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe, dfX, dfy, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['memory',\n",
      " 'steps',\n",
      " 'verbose',\n",
      " 'preprocess',\n",
      " 'clf',\n",
      " 'preprocess__n_jobs',\n",
      " 'preprocess__remainder',\n",
      " 'preprocess__sparse_threshold',\n",
      " 'preprocess__transformer_weights',\n",
      " 'preprocess__transformers',\n",
      " 'preprocess__verbose',\n",
      " 'preprocess__clmn_drpr',\n",
      " 'preprocess__enc',\n",
      " 'preprocess__imp_scale_augment',\n",
      " 'preprocess__enc__categories',\n",
      " 'preprocess__enc__drop',\n",
      " 'preprocess__enc__dtype',\n",
      " 'preprocess__enc__handle_unknown',\n",
      " 'preprocess__enc__sparse',\n",
      " 'preprocess__imp_scale_augment__memory',\n",
      " 'preprocess__imp_scale_augment__steps',\n",
      " 'preprocess__imp_scale_augment__verbose',\n",
      " 'preprocess__imp_scale_augment__imp',\n",
      " 'preprocess__imp_scale_augment__scaler',\n",
      " 'preprocess__imp_scale_augment__augment',\n",
      " 'preprocess__imp_scale_augment__imp__add_indicator',\n",
      " 'preprocess__imp_scale_augment__imp__copy',\n",
      " 'preprocess__imp_scale_augment__imp__fill_value',\n",
      " 'preprocess__imp_scale_augment__imp__missing_values',\n",
      " 'preprocess__imp_scale_augment__imp__strategy',\n",
      " 'preprocess__imp_scale_augment__imp__verbose',\n",
      " 'preprocess__imp_scale_augment__scaler__copy',\n",
      " 'preprocess__imp_scale_augment__scaler__with_mean',\n",
      " 'preprocess__imp_scale_augment__scaler__with_std',\n",
      " 'preprocess__imp_scale_augment__augment__n_jobs',\n",
      " 'preprocess__imp_scale_augment__augment__transformer_list',\n",
      " 'preprocess__imp_scale_augment__augment__transformer_weights',\n",
      " 'preprocess__imp_scale_augment__augment__verbose',\n",
      " 'preprocess__imp_scale_augment__augment__cluster',\n",
      " 'preprocess__imp_scale_augment__augment__original',\n",
      " 'preprocess__imp_scale_augment__augment__cluster__algorithm',\n",
      " 'preprocess__imp_scale_augment__augment__cluster__copy_x',\n",
      " 'preprocess__imp_scale_augment__augment__cluster__init',\n",
      " 'preprocess__imp_scale_augment__augment__cluster__max_iter',\n",
      " 'preprocess__imp_scale_augment__augment__cluster__n_clusters',\n",
      " 'preprocess__imp_scale_augment__augment__cluster__n_init',\n",
      " 'preprocess__imp_scale_augment__augment__cluster__n_jobs',\n",
      " 'preprocess__imp_scale_augment__augment__cluster__precompute_distances',\n",
      " 'preprocess__imp_scale_augment__augment__cluster__random_state',\n",
      " 'preprocess__imp_scale_augment__augment__cluster__tol',\n",
      " 'preprocess__imp_scale_augment__augment__cluster__verbose',\n",
      " 'clf__bootstrap',\n",
      " 'clf__ccp_alpha',\n",
      " 'clf__class_weight',\n",
      " 'clf__criterion',\n",
      " 'clf__max_depth',\n",
      " 'clf__max_features',\n",
      " 'clf__max_leaf_nodes',\n",
      " 'clf__max_samples',\n",
      " 'clf__min_impurity_decrease',\n",
      " 'clf__min_impurity_split',\n",
      " 'clf__min_samples_leaf',\n",
      " 'clf__min_samples_split',\n",
      " 'clf__min_weight_fraction_leaf',\n",
      " 'clf__n_estimators',\n",
      " 'clf__n_jobs',\n",
      " 'clf__oob_score',\n",
      " 'clf__random_state',\n",
      " 'clf__verbose',\n",
      " 'clf__warm_start']\n"
     ]
    }
   ],
   "source": [
    "print_params(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.6 s, sys: 205 ms, total: 12.8 s\n",
      "Wall time: 5.54 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preprocess',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='passthrough',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('clmn_drpr',\n",
       "                                                                         'drop',\n",
       "                                                                         ['Name',\n",
       "                                                                          'Ticket',\n",
       "                                                                          'Cabin']),\n",
       "                                                                        ('enc',\n",
       "                                                                         OneHotEncoder(categories='auto',\n",
       "                                                                                       drop='first',\n",
       "                                                                                       dtype=<class 'numpy.float64'>,\n",
       "                                                                                       handle_unknown='err...\n",
       "                                                               min_samples_split=2,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'preprocess__imp_scale_augment__augment__cluster__n_clusters': range(2, 12, 2)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'preprocess__imp_scale_augment__augment__cluster__n_clusters': range(2, 12, 2)}\n",
    "grid = GridSearchCV(pipe, param_grid)\n",
    "grid.fit(dfX, dfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8122008506316257"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:titansurv] *",
   "language": "python",
   "name": "conda-env-titansurv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
